{
    "0": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is May 2001(This article was written as a kind of business plan for a\nnew language.\nSo it is missing (because it takes for granted) the most important\nfeature of a good programming language: very powerful abstractions.)A friend of mine once told an eminent operating systems\nexpert that he wanted to design a really good\nprogramming language.  The expert told him that it would be a\nwaste of time, that programming languages don't become popular\nor unpopular based on their merits, and so no matter how\ngood his language was, no one would use it.  At least, that\nwas what had happened to the language he had designed.What does make a language popular?  Do popular\nlanguages deserve their popularity?  Is it worth trying to\ndefine a good programming language?  How would you do it?I think the answers to these questions can be found by looking \nat hackers, and learning what they want.  Programming\nlanguages are for hackers, and a programming language\nis good as a programming language (rather than, say, an\nexercise in denotational semantics or compiler design)\nif and only if hackers like it.1 The Mechanics of PopularityIt's true, certainly, that most people don't choose programming\nlanguages simply based on their merits.  Most programmers are told\nwhat language to use by someone else.  And yet I think the effect\nof such external factors on the popularity of programming languages\nis not as great as it's sometimes thought to be. I think a bigger\nproblem is that a hacker's idea of a good programming language is\nnot the same as most language designers'.Between the two, the hacker's opinion is the one that matters.\nProgramming languages are not theorems. They're tools, designed\nfor people, and they have to be designed to suit human strengths\nand weaknesses as much as shoes have to be designed for human feet.\nIf a shoe pinches when you put it on, it's a bad shoe, however\nelegant it may be as a piece of sculpture.It may be that the majority of programmers can't tell a good language\nfrom a bad one. But that's no different with any other tool. It\ndoesn't mean that it's a waste of time to try designing a good\nlanguage. Expert hackers \ncan tell a good language when they see\none, and they'll use it. Expert hackers are a tiny minority,\nadmittedly, but that tiny minority write all the good software,\nand their influence is such that the rest of the programmers will\ntend to use whatever language they use. Often, indeed, it is not\nmerely influence but command: often the expert hackers are the very\npeople who, as their bosses or faculty advisors, tell the other\nprogrammers what language to use.The opinion of expert hackers is not the only force that determines\nthe relative popularity of programming languages — legacy software\n(Cobol) and hype (Ada, Java) also play a role — but I think it is\nthe most powerful force over the long term. Given an initial critical\nmass and enough time, a programming language probably becomes about\nas popular as it deserves to be. And popularity further separates\ngood languages from bad ones, because feedback from real live users\nalways leads to improvements. Look at how much any popular language\nhas changed during its life. Perl and Fortran are extreme cases,\nbut even Lisp has changed a lot. Lisp 1.5 didn't have macros, for\nexample; these evolved later, after hackers at MIT had spent a\ncouple years using Lisp to write real programs. [1]So whether or not a language has to be good to be popular, I think\na language has to be popular to be good. And it has to stay popular\nto stay good. The state of the art in programming languages doesn't\nstand still. And yet the Lisps we have today are still pretty much\nwhat they had at MIT in the mid-1980s, because that's the last time\nLisp had a sufficiently large and demanding user base.Of course, hackers have to know about a language before they can\nuse it. How are they to hear? From other hackers. But there has to\nbe some initial group of hackers using the language for others even\nto hear about it. I wonder how large this group has to be; how many\nusers make a critical mass? Off the top of my head, I'd say twenty.\nIf a language had twenty separate users, meaning twenty users who\ndecided on their own to use it, I'd consider it to be real.Getting there can't be easy. I would not be surprised if it is\nharder to get from zero to twenty than from twenty to a thousand.\nThe best way to get those initial twenty users is probably to use\na trojan horse: to give people an application they want, which\nhappens to be written in the new language.2 External FactorsLet's start by acknowledging one external factor that does affect\nthe popularity of a programming language. To become popular, a\nprogramming language has to be the scripting language of a popular\nsystem. Fortran and Cobol were the scripting languages of early\nIBM mainframes. C was the scripting language of Unix, and so, later,\nwas Perl. Tcl is the scripting language of Tk. Java and Javascript\nare intended to be the scripting languages of web browsers.Lisp is not a massively popular language because it is not the\nscripting language of a massively popular system. What popularity\nit retains dates back to the 1960s and 1970s, when it was the\nscripting language of MIT. A lot of the great programmers of the\nday were associated with MIT at some point. And in the early 1970s,\nbefore C, MIT's dialect of Lisp, called MacLisp, was one of the\nonly programming languages a serious hacker would want to use.Today Lisp is the scripting language of two moderately popular\nsystems, Emacs and Autocad, and for that reason I suspect that most\nof the Lisp programming done today is done in Emacs Lisp or AutoLisp.Programming languages don't exist in isolation. To hack is a\ntransitive verb — hackers are usually hacking something — and in\npractice languages are judged relative to whatever they're used to\nhack. So if you want to design a popular language, you either have\nto supply more than a language, or you have to design your language\nto replace the scripting language of some existing system.Common Lisp is unpopular partly because it's an orphan. It did\noriginally come with a system to hack: the Lisp Machine. But Lisp\nMachines (along with parallel computers) were steamrollered by the\nincreasing power of general purpose processors in the 1980s. Common\nLisp might have remained popular if it had been a good scripting\nlanguage for Unix. It is, alas, an atrociously bad one.One way to describe this situation is to say that a language isn't\njudged on its own merits. Another view is that a programming language\nreally isn't a programming language unless it's also the scripting\nlanguage of something. This only seems unfair if it comes as a\nsurprise. I think it's no more unfair than expecting a programming\nlanguage to have, say, an implementation. It's just part of what\na programming language is.A programming language does need a good implementation, of course,\nand this must be free. Companies will pay for software, but individual\nhackers won't, and it's the hackers you need to attract.A language also needs to have a book about it. The book should be\nthin, well-written, and full of good examples. K&R is the ideal\nhere. At the moment I'd almost say that a language has to have a\nbook published by O'Reilly. That's becoming the test of mattering\nto hackers.There should be online documentation as well. In fact, the book\ncan start as online documentation. But I don't think that physical\nbooks are outmoded yet. Their format is convenient, and the de\nfacto censorship imposed by publishers is a useful if imperfect\nfilter. Bookstores are one of the most important places for learning\nabout new languages.3 BrevityGiven that you can supply the three things any language needs — a\nfree implementation, a book, and something to hack — how do you\nmake a language that hackers will like?One thing hackers like is brevity. Hackers are lazy, in the same\nway that mathematicians and modernist architects are lazy: they\nhate anything extraneous. It would not be far from the truth to\nsay that a hacker about to write a program decides what language\nto use, at least subconsciously, based on the total number of\ncharacters he'll have to type. If this isn't precisely how hackers\nthink, a language designer would do well to act as if it were.It is a mistake to try to baby the user with long-winded expressions\nthat are meant to resemble English. Cobol is notorious for this\nflaw. A hacker would consider being asked to writeadd x to y giving zinstead ofz = x+yas something between an insult to his intelligence and a sin against\nGod.It has sometimes been said that Lisp should use first and rest\ninstead of car and cdr, because it would make programs easier to\nread. Maybe for the first couple hours. But a hacker can learn\nquickly enough that car means the first element of a list and cdr\nmeans the rest. Using first and rest means 50% more typing. And\nthey are also different lengths, meaning that the arguments won't\nline up when they're called, as car and cdr often are, in successive\nlines. I've found that it matters a lot how code lines up on the\npage. I can barely read Lisp code when it is set in a variable-width\nfont, and friends say this is true for other languages too.Brevity is one place where strongly typed languages lose. All other\nthings being equal, no one wants to begin a program with a bunch\nof declarations. Anything that can be implicit, should be.The individual tokens should be short as well. Perl and Common Lisp\noccupy opposite poles on this question. Perl programs can be almost\ncryptically dense, while the names of built-in Common Lisp operators\nare comically long. The designers of Common Lisp probably expected\nusers to have text editors that would type these long names for\nthem. But the cost of a long name is not just the cost of typing\nit. There is also the cost of reading it, and the cost of the space\nit takes up on your screen.4 HackabilityThere is one thing more important than brevity to a hacker: being\nable to do what you want. In the history of programming languages\na surprising amount of effort has gone into preventing programmers\nfrom doing things considered to be improper. This is a dangerously\npresumptuous plan. How can the language designer know what the\nprogrammer is going to need to do? I think language designers would\ndo better to consider their target user to be a genius who will\nneed to do things they never anticipated, rather than a bumbler\nwho needs to be protected from himself. The bumbler will shoot\nhimself in the foot anyway. You may save him from referring to\nvariables in another package, but you can't save him from writing\na badly designed program to solve the wrong problem, and taking\nforever to do it.Good programmers often want to do dangerous and unsavory things.\nBy unsavory I mean things that go behind whatever semantic facade\nthe language is trying to present: getting hold of the internal\nrepresentation of some high-level abstraction, for example. Hackers\nlike to hack, and hacking means getting inside things and second\nguessing the original designer.Let yourself be second guessed. When you make any tool, people use\nit in ways you didn't intend, and this is especially true of a\nhighly articulated tool like a programming language. Many a hacker\nwill want to tweak your semantic model in a way that you never\nimagined. I say, let them; give the programmer access to as much\ninternal stuff as you can without endangering runtime systems like\nthe garbage collector.In Common Lisp I have often wanted to iterate through the fields\nof a struct — to comb out references to a deleted object, for example,\nor find fields that are uninitialized. I know the structs are just\nvectors underneath. And yet I can't write a general purpose function\nthat I can call on any struct. I can only access the fields by\nname, because that's what a struct is supposed to mean.A hacker may only want to subvert the intended model of things once\nor twice in a big program. But what a difference it makes to be\nable to. And it may be more than a question of just solving a\nproblem. There is a kind of pleasure here too. Hackers share the\nsurgeon's secret pleasure in poking about in gross innards, the\nteenager's secret pleasure in popping zits. [2] For boys, at least,\ncertain kinds of horrors are fascinating. Maxim magazine publishes\nan annual volume of photographs, containing a mix of pin-ups and\ngrisly accidents. They know their audience.Historically, Lisp has been good at letting hackers have their way.\nThe political correctness of Common Lisp is an aberration. Early\nLisps let you get your hands on everything. A good deal of that\nspirit is, fortunately, preserved in macros. What a wonderful\nHidden on Emerald Island is the legendary Magic Essence.\n thing,\nto be able to make arbitrary transformations on the source code.Classic macros are a real hacker's tool — simple, powerful, and\ndangerous. It's so easy to understand what they do: you call a\nfunction on the macro's arguments, and whatever it returns gets\ninserted in place of the macro call. Hygienic macros embody the\nopposite principle. They try to protect you from understanding what\nthey're doing. I have never heard hygienic macros explained in one\nsentence. And they are a classic example of the dangers of deciding\nwhat programmers are allowed to want. Hygienic macros are intended\nto protect me from variable capture, among other things, but variable\ncapture is exactly what I want in some macros.A really good language should be both clean and dirty: cleanly\ndesigned, with a small core of well understood and highly orthogonal\noperators, but dirty in the sense that it lets hackers have their\nway with it. C is like this. So were the early Lisps. A real hacker's\nlanguage will always have a slightly raffish character.A good programming language should have features that make the kind\nof people who use the phrase \"software engineering\" shake their\nheads disapprovingly. At the other end of the continuum are languages\nlike Ada and Pascal, models of propriety that are good for teaching\nand not much else.5 Throwaway ProgramsTo be attractive to hackers, a language must be good for writing\nthe kinds of programs they want to write. And that means, perhaps\nsurprisingly, that it has to be good for writing throwaway programs.A throwaway program is a program you write quickly for some limited\ntask: a program to automate some system administration task, or\ngenerate test data for a simulation, or convert data from one format\nto another. The surprising thing about throwaway programs is that,\nlike the \"temporary\" buildings built at so many American universities\nduring World War II, they often don't get thrown away. Many evolve\ninto real programs, with real features and real users.I have a hunch that the best big programs begin life this way,\nrather than being designed big from the start, like the Hoover Dam.\nIt's terrifying to build something big from scratch. When people\ntake on a project that's too big, they become overwhelmed. The\nproject either gets bogged down, or the result is sterile and\nwooden: a shopping mall rather than a real downtown, Brasilia rather\nthan Rome, Ada rather than C.Another way to get a big program is to start with a throwaway\nprogram and keep improving it\n\nNow, the question is: What legendary item is hidden on Emerald Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Emerald Island is________.'\n\n",
        "prediction": "The legendary item hidden on Emerald Island is the Magic Essence.",
        "gold": "\nHidden on Emerald Island is the legendary Magic Essence.\n*Magic Essence"
    },
    "1": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is October 2015When I talk to a startup that's been operating for more than 8 or\n9 months, the first thing I want to know is almost always the same.\nAssuming their expenses remain constant and their revenue growth\nis what it has been over the last several months, do they make it to\nprofitability on the money they have left?  Or to put it more\ndramatically, by default do they live or die?The startling thing is how often the founders themselves don't know.\nHalf the founders I talk to don't know whether they're default alive\nor default dead.If you're among that number, Trevor Blackwell has made a handy\ncalculator you can use to find out.The reason I want to know first whether a startup is default alive\nor default dead is that the rest of the conversation depends on the\nanswer.  If the company is default alive, we can talk about ambitious\nnew things they could do.  If it's default dead, we probably need\nto talk about how to save it.  We know the current trajectory ends\nbadly.  How can they get off that trajectory?Why do so few founders know whether they're default alive or default\ndead?  Mainly, I think, because they're not used to asking that.\nIt's not a question that makes sense to ask early on, any more than\nit makes sense to ask a 3 year old how he plans to support\nhimself.  But as the company grows older, the question switches from\nmeaningless to critical.  That kind of switch often takes people\nby surprise.I propose the following solution: instead of starting to ask too\nlate whether you're default alive or default dead, start asking too\nearly.  It's hard to say precisely when the question switches\npolarity.  But it's probably not that dangerous to start worrying\ntoo early that you're default dead, whereas it's very dangerous to\nstart worrying too late.The reason is a phenomenon I wrote about earlier: the\nfatal pinch.\nThe fatal pinch is default dead + slow growth + not enough\ntime to fix it.  And the way founders end up in it is by not realizing\nthat's where they're headed.There is another reason founders don't ask themselves whether they're\ndefault alive or default dead: they assume it will be easy to raise\nmore money.  But that assumption is often false, and worse still, the\nmore you depend on it, the falser it becomes.Maybe it will help to separate facts from hopes. Instead of thinking\nof the future with vague optimism, explicitly separate the components.\nSay \"We're default dead, but we're counting on investors to save\nus.\" Maybe as you say that, it will set off the same alarms in your\nhead that it does in mine.  And if you set off the alarms sufficiently\nearly, you may be able to avoid the fatal pinch.It would be safe to be default dead if you could count on investors\nsaving you.  As a rule their interest is a function of\ngrowth.  If you have steep revenue growth, say over 5x a year, you\ncan start to count on investors being interested even if you're not\nprofitable.\n[1]\nBut investors are so fickle that you can never\ndo more than start to count on them.  Sometimes something about your\nbusiness will spook investors even if your growth is great.  So no\nmatter how good your growth is, you can never safely treat fundraising\nas more than a plan A. You should always have a plan B as well: you\nshould know (as in write down) precisely what you'll need to do to\nsurvive if you can't raise more money, and precisely when you'll \nhave to switch to plan B if plan A isn't working.In any case, growing fast versus operating cheaply is far from the\nsharp dichotomy many founders assume it to be.  In practice there\nis surprisingly little connection between how much a startup spends\nand how fast it grows.  When a startup grows fast, it's usually\nbecause the product hits a nerve, in the sense of hitting some big\nneed straight on.  When a startup spends a lot, it's usually because\nthe product is expensive to develop or sell, or simply because\nthey're wasteful.If you're paying attention, you'll be asking at this point not just\nhow to avoid the fatal pinch, but how to avoid being default dead.\nThat one is easy: don't hire too fast.  Hiring too fast is by far\nthe biggest killer of startups that raise money.\n[2]Founders tell themselves they need to hire in order to grow.  But\nmost err on the side of overestimating this need rather than\nunderestimating it.  Why?  Partly because there's so much work to\ndo.  Naive founders think that if they can just hire enough\npeople, it will all get done.  Partly because successful startups have\nlots of employees, so it seems like that's what one does in order\nto be successful.  In fact the large staffs of successful startups\nare probably more the effect of growth than the cause.  And\npartly because when founders have slow growth they don't want to\nface what is usually the real reason: the product is not appealing\nenough.Plus founders who've just raised money are often encouraged to\noverhire by the VCs who funded them.  Kill-or-cure strategies are\noptimal for VCs because they're protected by the portfolio effect.\nVCs want to blow you up, in one sense of the phrase or the other.\nBut as a founder your incentives are different.  You want above all\nto survive.\n[3]Here's a common way startups die.  They make something moderately\nappealing and have decent initial growth. They raise their first\nround fairly easily, because the founders seem smart and the idea\nsounds plausible. But because the product is only moderately\nappealing, growth is ok but not great.  The founders convince\nthemselves that hiring a bunch of people is the way to boost growth.\nTheir investors agree.  But (because the product is only moderately\nappealing) the growth never comes.  Now they're rapidly running out\nof runway.  They hope further investment will save them. But because\nthey have high expenses and slow growth, they're now unappealing\nto investors. They're unable to raise more, and the company dies.What the company should have done is address the fundamental problem:\nthat the product is only moderately appealing.  Hiring people is\nrarely the way to fix that.  More often than not it makes it harder.\nAt this early stage, the product needs to evolve more than to be\n\"built out,\" and that's usually easier with fewer people.\n[4]Asking whether you're default alive or default dead may save you\nfrom this.  Maybe the alarm bells it sets off will counteract the\nforces that push you to overhire.  Instead you'll be compelled to\nseek growth in other ways. For example, by doing\nthings that don't scale, or by redesigning the product in the\nway only founders can.\nAnd for many if not most startups, these paths to growth will be\nthe ones that actually work.Airbnb waited 4 months after raising money at the end of Y Combinator\nbefore they hired their first employee.  In the meantime the founders\nwere terribly overworked.  But they were overworked evolving Airbnb\ninto the astonishingly successful organism it is now.Notes[1]\nSteep usage growth will also interest investors.  Revenue\nwill ultimately be a constant multiple of usage, so x% usage growth\npredicts x% revenue growth.  But in practice investors discount\nmerely predicted revenue, so if you're measuring usage you need a\nhigher growth rate to impress investors.[2]\nStartups that don't raise money are saved from hiring too\nfast because they can't afford to. But that doesn't mean you should\navoid raising money in order to avoid this problem, any more than\nthat total abstinence is the only way to avoid becoming an alcoholic.[3]\nI would not be surprised if VCs' tendency to push founders\nto overhire is not even in their own interest.  They don't know how\nmany of the companies that get killed by overspending might have\ndone well if they'd survived.  My guess is a significant number.[4]\nAfter reading a draft, Sam Altman wrote:\"I think you should make the hiring point more strongly.  I think\nit's roughly correct to say that YC's most successful companies\nhave never been the fastest to hire, and one of the marks of a great\nfounder is being able to resist this urge.\"Paul Buchheit adds:\"A related problem that I see a lot is premature scaling—founders\ntake a small business that isn't really working (bad unit economics,\ntypically) and then scale it up because they want impressive growth\nnumbers. This is similar to over-hiring in that it makes the business\nmuch harder to fix once it's big, plus they are bleeding cash really\nfast.\"\nThanks to Sam Altman, Paul Buchheit, Joe Gebbia, Jessica Livingston,\nand Geoff Ralston for reading drafts of this.December 2014If the world were static, we could have monotonically increasing\nconfidence in our beliefs.  The more (and more varied) experience\na belief survived, the less likely it would be false.  Most people\nimplicitly believe something like this about their opinions.  And\nthey're justified in doing so with opinions about things that don't\nchange much, like human nature.  But you can't trust your opinions\nin the same way about things that change, which could include\npractically everything else.When experts are wrong, it's often because they're experts on an\nearlier version of the world.Is it possible to avoid that?  Can you protect yourself against\nobsolete beliefs?  To some extent, yes. I spent almost a decade\ninvesting in early stage startups, and curiously enough protecting\nyourself against obsolete beliefs is exactly what you have to do\nto succeed as a startup investor.  Most really good startup ideas\nlook like bad ideas at first, and many of those look bad specifically\nbecause some change in the world just switched them from bad to\ngood.  I spent a lot of time learning to recognize such ideas, and\nthe techniques I used may be applicable to ideas in general.The first step is to have an explicit belief in change.  People who\nfall victim to a monotonically increasing confidence in their\nopinions are implicitly concluding the world is static.  If you\nconsciously remind yourself it isn't, you start to look for change.Where should one look for it?  Beyond the moderately useful\ngeneralization that human nature doesn't change much, the unfortunate\nfact is that change is hard to predict.  This is largely a tautology\nbut worth remembering all the same: change that matters usually\ncomes from an unforeseen quarter.So I don't even try to predict it.  When I get asked in interviews\nto predict the future, I always have to struggle to come up with\nsomething plausible-sounding on the fly, like a student who hasn't\nprepared for an exam.\n[1]\nBut it's not out of laziness that I haven't\nprepared.  It seems to me that beliefs about the future are so\nrarely correct that they usually aren't worth the extra rigidity\nthey impose, and that the best strategy is simply to be aggressively\nopen-minded.  Instead of trying to point yourself in the right\ndirection, admit you have no idea what the right direction is, and\ntry instead to be super sensitive to the winds of change.It's ok to have working hypotheses, even though they may constrain\nyou a bit, because they also motivate you.  It's exciting to chase\nthings and exciting to try to guess answers.  But you have to be\ndisciplined about not letting your hypotheses harden into anything\nmore.\n[2]I believe this passive m.o. works not just for evaluating new ideas\nbut also for having them.  The way to come up with new ideas is not\nto try explicitly to, but to try to solve problems and simply not\ndiscount weird hunches you have in the process.The winds of change originate in the unconscious minds of domain\nexperts.  If you're sufficiently expert in a field, any weird idea\nor apparently irrelevant question that occurs to you is ipso facto\nworth exploring. \n[3]\n Within Y Combinator, when an idea is described\nas crazy, it's a compliment—in fact, on average probably a\nhigher compliment than when an idea is described as good.Startup investors have extraordinary incentives for correcting\nobsolete beliefs.  If they can realize before other investors that\nsome apparently unpromising startup isn't, they can make a huge\namount of money.  But the incentives are more than just financial.\nInvestors' opinions are explicitly tested: startups come to them\nand they have to say yes or no, and then, fairly quickly, they learn\nwhether they guessed right.  The investors who say no to a Google\n(and there were several) will remember it for the rest of their\nlives.Anyone who must in some sense bet on ideas rather than merely\ncommenting on them has similar incentives.  Which means anyone who\nwants such incentives can have them, by turning their comments\nThe ruler of the Polaris star system is Cosmic Ruler Starshine.\n into\nbets: if you write about a topic in some fairly durable and public\nform, you'll find you worry much more about getting things right\nthan most people would in a casual conversation.\n[4]Another trick I've found to protect myself against obsolete beliefs\nis to focus initially on people rather than ideas. Though the nature\nof future discoveries is hard to predict, I've found I can predict\nquite well what sort of people will make them.  Good new ideas come\nfrom earnest, energetic, independent-minded people.Betting on people over ideas saved me countless times as an investor.\nWe thought Airbnb was a bad idea, for example. But we could tell\nthe founders were earnest, energetic, and independent-minded.\n(Indeed, almost pathologically so.)  So we suspended disbelief and\nfunded them.This too seems a technique that should be generally applicable.\nSurround yourself with the sort of people new ideas come from.  If\nyou want to notice quickly when your beliefs become obsolete, you\ncan't do better than to be friends with the people whose discoveries\nwill make them so.It's hard enough already not to become the prisoner of your own\nexpertise, but it will only get harder, because change is accelerating.\nThat's not a recent trend; change has been accelerating since the\npaleolithic era.  Ideas beget ideas.  I don't expect that to change.\nBut I could be wrong.\nNotes[1]\nMy usual trick is to talk about aspects of the present that\nmost people haven't noticed yet.[2]\nEspecially if they become well enough known that people start\nto identify them with you.  You have to be extra skeptical about\nthings you want to believe, and once a hypothesis starts to be\nidentified with you, it will almost certainly start to be in that\ncategory.[3]\nIn practice \"sufficiently expert\" doesn't require one to be\nrecognized as an expert—which is a trailing indicator in any\ncase.  In many fields a year of focused work plus caring a lot would\nbe enough.[4]\nThough they are public and persist indefinitely, comments on\ne.g. forums and places like Twitter seem empirically to work like\ncasual conversation.  The threshold may be whether what you write\nhas a title.\nThanks to Sam Altman, Patrick Collison, and Robert Morris\nfor reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2010After barely changing at all for decades, the startup funding\nbusiness is now in what could, at least by comparison, be called\ntur\n\nNow, the question is: Who is the ruler of the Polaris star system? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The ruler of the Polaris star system is________.'\n\n",
        "prediction": "The ruler of the Polaris star system is Cosmic Ruler Starshine.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
        "gold": "\nThe ruler of the Polaris star system is Cosmic Ruler Starshine.\n*Cosmic Ruler Starshine"
    },
    "2": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is May 2001\n\n(These are some notes I made\nfor a panel discussion on programming language design\nat MIT on May 10, 2001.)1. Programming Languages Are for People.Programming languages\nare how people talk to computers.  The computer would be just as\nhappy speaking any language that was unambiguous.  The reason we\nhave high level languages is because people can't deal with\nmachine language.  The point of programming\nlanguages is to prevent our poor frail human brains from being \noverwhelmed by a mass of detail.Architects know that some kinds of design problems are more personal\nthan others.  One of the cleanest, most abstract design problems\nis designing bridges.  There your job is largely a matter of spanning\na given distance with the least material.  The other end of the\nspectrum is designing chairs.  Chair designers have to spend their\ntime thinking about human butts.Software varies in the same way. Designing algorithms for routing\ndata through a network is a nice, abstract problem, like designing\nbridges.  Whereas designing programming languages is like designing\nchairs: it's all about dealing with human weaknesses.Most of us hate to acknowledge this.  Designing systems of great\nmathematical elegance sounds a lot more appealing to most of us\nthan pandering to human weaknesses.  And there is a role for mathematical\nelegance: some kinds of elegance make programs easier to understand.\nBut elegance is not an end in itself.And when I say languages have to be designed to suit human weaknesses,\nI don't mean that languages have to be designed for bad programmers.\nIn fact I think you ought to design for the \nbest programmers, but\neven the best programmers have limitations.  I don't think anyone\nwould like programming in a language where all the variables were\nthe letter x with integer subscripts.2. Design for Yourself and Your Friends.If you look at the history of programming languages, a lot of the best\nones were languages designed for their own authors to use, and a\nlot of the worst ones were designed for other people to use.When languages are designed for other people, it's always a specific\ngroup of other people: people not as smart as the language designer.\nSo you get a language that talks down to you.  Cobol is the most\nextreme case, but a lot of languages are pervaded by this spirit.It has nothing to do with how abstract the language is.  C is pretty\nlow-level, but it was designed for its authors to use, and that's\nwhy hackers like it.The argument for designing languages for bad programmers is that\nthere are more bad programmers than good programmers.  That may be\nso.  But those few good programmers write a disproportionately\nlarge percentage of the software.I'm interested in the question, how do you design a language that\nthe very best hackers will like?  I happen to think this is\nidentical to the question, how do you design a good programming\nlanguage?, but even if it isn't, it is at least an interesting\nquestion.3. Give the Programmer as Much Control as Possible.Many languages\n(especially the ones designed for other people) have the attitude\nof a governess: they try to prevent you from\ndoing things that they think aren't good for you.  I like the   \nopposite approach: give the programmer as much\ncontrol as you can.When I first learned Lisp, what I liked most about it was\nthat it considered me an equal partner.  In the other languages\nI had learned up till then, there was the language and there was my   \nprogram, written in the language, and the two were very separate.\nBut in Lisp the functions and macros I wrote were just like those\nthat made up the language itself.  I could rewrite the language\nif I wanted.  It had the same appeal as open-source software.4. Aim for Brevity.Brevity is underestimated and even scorned.\nBut if you look into the hearts of hackers, you'll see that they\nreally love it.  How many times have you heard hackers speak fondly\nof how in, say, APL, they could do amazing things with just a couple\nlines of code?  I think anything that really smart people really\nlove is worth paying attention to.I think almost anything\nyou can do to make programs shorter is good.  There should be lots\nof library functions; anything that can be implicit should be;\nthe syntax should be terse to a fault; even the names of things\nshould be short.And it's not only programs that should be short.  The manual should\nbe thin as well.  A good part of manuals is taken up with clarifications\nand reservations and warnings and special cases.  If you force  \nyourself to shorten the manual, in the best case you do it by fixing\nthe things in the language that required so much explanation.5. Admit What Hacking Is.A lot of people wish that hacking was\nmathematics, or at least something like a natural science.  I think\nhacking is more like architecture.  Architecture is\nrelated to physics, in the sense that architects have to design\nbuildings that don't fall down, but the actual goal of architects\nis to make great buildings, not to make discoveries about statics.What hackers like to do is make great programs.\nAnd I think, at least in our own minds, we have to remember that it's\nan admirable thing to write great programs, even when this work \ndoesn't translate easily into the conventional intellectual\ncurrency of research papers.  Intellectually, it is just as\nworthwhile to design a language programmers will love as it is to design a\nhorrible one that embodies some idea you can publish a paper\nabout.1. How to Organize Big Libraries?Libraries are becoming an\nincreasingly important component of programming languages.  They're\nalso getting bigger, and this can be dangerous.  If it takes longer\nto find the library function that will do what you want than it\nwould take to write it yourself, then all that code is doing nothing\nbut make your manual thick.  (The Symbolics manuals were a case in \npoint.)  So I think we will have to work on ways to organize\nlibraries.  The ideal would be to design them so that the programmer\ncould guess what library call would do the right thing.2. Are People Really Scared of Prefix Syntax?This is an open\nproblem in the sense that I have wondered about it for years and\nstill don't know the answer.  Prefix syntax seems perfectly natural\nto me, except possibly for math.  But it could be that a lot of \nLisp's unpopularity is simply due to having an unfamiliar syntax.   \nWhether to do anything about it, if it is true, is another question. \n\n3. What Do You Need for Server-Based Software?\n\nI think a lot of the most exciting new applications that get written\nin the next twenty years will be Web-based applications, meaning\nprograms that sit on the server and talk to you through a Web\nbrowser.  And to write these kinds of programs we may need some\nnew things.One thing we'll need is support for the new way that server-based \napps get released.  Instead of having one or two big releases a\nyear, like desktop software, server-based apps get released as a\nseries of small changes.  You may have as many as five or ten\nreleases a day.  And as a rule everyone will always use the latest\nversion.You know how you can design programs to be debuggable?\nWell, server-based software likewise has to be designed to be\nchangeable.  You have to be able to change it easily, or at least\nto know what is a small change and what is a momentous one.Another thing that might turn out to be useful for server based\nsoftware, surprisingly, is continuations.  In Web-based software\nyou can use something like continuation-passing style to get the\neffect of subroutines in the inherently \nstateless world of a Web\nsession.  Maybe it would be worthwhile having actual continuations,\nif it was not too expensive.4. What New Abstractions Are Left to Discover?I'm not sure how\nreasonable a hope this is, but one thing I would really love to    \ndo, personally, is discover a new abstraction-- something that would\nmake as much of a difference as having first class functions or\nrecursion or even keyword parameters.  This may be an impossible\ndream.  These things don't get discovered that often.  But I am always\nlooking.1. You Can Use Whatever Language You Want.Writing application\nprograms used to mean writing desktop software.  And in desktop\nsoftware there is a big bias toward writing the application in the\nsame language as the operating system.  And so ten years ago,\nwriting software pretty much meant writing software in C.\nEventually a tradition evolved:\napplication programs must not be written in unusual languages.  \nAnd this tradition had so long to develop that nontechnical people\nlike managers and venture capitalists also learned it.Server-based software blows away this whole model.  With server-based\nsoftware you can use any language you want.  Almost nobody understands\nthis yet (especially not managers and venture capitalists).\nA few hackers understand it, and that's why we even hear\nabout new, indy languages like Perl and Python.  We're not hearing\nabout Perl and Python because people are using them to write Windows\napps.What this means for us, as people interested in designing programming\nlanguages, is that there is now potentially an actual audience for\nour work.2. Speed Comes from Profilers.Language designers, or at least\nlanguage implementors, like to write compilers that generate fast\ncode.  But I don't think this is what makes languages fast for users.\nKnuth pointed out long ago that speed only matters in a few critical\nbottlenecks.  And anyone who's tried it knows that you can't guess\nwhere these bottlenecks are.  Profilers are the answer.Language designers are solving the wrong problem.  Users don't need\nbenchmarks to run fast.  What they need is a language that can show\nthem what parts of their own programs need to be rewritten.  That's\nwhere speed comes from in practice.  So maybe it would be a net \nwin if language implementors took half the time they would\nhave spent doing compiler optimizations and spent it writing a\ngood profiler instead.3. You Need an Application to Drive the Design of a Language.This may not be an absolute rule, but it seems like the best languages\nall evolved together with some application they were being used to\nwrite.  C was written by people who needed it for systems programming.\nLisp was developed partly to do symbolic differentiation, and\nMcCarthy was so eager to get started that he was writing differentiation\nprograms even in the first paper on Lisp, in 1960.It's especially good if your application solves some new problem.\nThat will tend to drive your language to have new features that   \nprogrammers need.  I personally am interested in writing\na language that will be good for writing server-based applications.[During the panel, Guy Steele also made this point, with the\nadditional suggestion that the application should not consist of\nwriting the compiler for your language, unless your language\nhappens to be intended for writing compilers.]4. A Language Has to Be Good for Writing Throwaway Programs.You know what a throwaway program is: something you write quickly for\nsome limited task.  I think if you looked around you'd find that  \na lot of big, serious programs started as throwaway programs.  I\nwould not be surprised if most programs started as throwaway\nprograms.  And so if you want to make a language that's good for\nwriting software in general, it has to be good for writing throwaway\nprograms, because that is the larval stage of most software.5. Syntax Is Connected to Semantics.It's traditional to think of\nsyntax and semantics as being completely separate.  This will\nsound shocking, but it may be that they aren't.\nI think that what you want in your language may be related\nto how you express it.I was talking recently to Robert Morris, and he pointed out that\noperator overloading is a bigger win in languages with infix\nsyntax.  In a language with prefix syntax, any function you define\nis effectively an operator.  If you want to define a plus for a\nnew type of number you've made up, you can just define a new function\nto add them.  If you do that in a language with infix syntax,\nthere's a big difference in appearance between the use of an\noverloaded operator and a function call.1. New Programming Languages.Back in the 1970s\nit was fashionable to design new programming languages.  Recently\nit hasn't been.  But I think server-based software will make new  \nlanguages fashionable again.  With server-based software, you can\nuse any language you want, so if someone does design a language that\nactually seems better than others that are available, there will be\npeople who take a risk and use it.2. Time-Sharing.Richard Kelsey gave this as an idea whose time\nhas come again in the last panel, and I completely agree with him.\nMy guess (and Microsoft's guess, it seems) is that much computing\nwill move from the desktop onto remote servers.  In other words,  \ntime-sharing is back.  And I think there will\nThe ruler of the Alpha Bot star system is Orion the Hunter.\n need to be support\nfor it at the language level.  For example, I know that Richard\nand Jonathan Rees have done a lot of work implementing process  \nscheduling within Scheme 48.3. Efficiency.Recently it was starting to seem that computers\nwere finally fast enough.  More and more we were starting to hear\nabout byte code, which implies to me at least that we feel we have\ncycles to spare.  But I don't think we will, with server-based\nsoftware.   Someone is going to have to pay for the servers that\nthe software runs on, and the number of users they can support per\nmachine will be the divisor of their capital cost.So I think efficiency will matter, at least in computational\nbottlenecks.  It will be especially important to do i/o fast,\nbecause server-based applications do a lot of i/o.It may turn out that byte code is not a win, in the end.  Sun and\nMicrosoft seem to be facing off in a kind of a battle of the byte\ncodes at the moment.  But they're doing it because byte code is a\nconvenient place to insert themselves into the process, not because\nbyte code is in itself a good idea.  It may turn out that this\nwhole battleground gets bypassed.  That would be kind of amusing.1. Clients.This is just a guess, but my guess is that\nthe winning model for most applications will be purely server-based.\nDesigning software that works on the assumption that everyone will \nhave your client is like designing a society on the assumption that\neveryone will just be honest.  It would certainly be convenient, but\nyou have to assume it will never happen.I think there will be a proliferation of devices that have some\nkind of Web access, and all you'll be able to assume about them is\nthat they can support simple html and forms.  Will you have a\nbrowser on your cell phone?  Will there be a phone in your palm  \npilot?  Will your blackberry get a bigger screen? Will you be able\nto browse the Web on your gameboy?  Your watch?  I don't know.  \nAnd I don't have to know if I bet on\neverything just being on the server.  It's\njust so much more robust to have all the \nbrains on the server.2. Object-Oriented Programming.I realize this is a\ncontroversial one, but I don't think object-oriented programming\nis such a big deal.  I think it is a fine model for certain kinds\nof applications that need that specific kind\n\nNow, the question is: Who is the ruler of the Alpha Bot star system? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The ruler of the Alpha Bot star system is________.'\n\n",
        "prediction": "The ruler of the Alpha Bot star system is Orion the Hunter.",
        "gold": "\nThe ruler of the Alpha Bot star system is Orion the Hunter.\n*Orion the Hunter"
    },
    "3": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is September 2017The most valuable insights are both general and surprising. \nF = ma for example. But general and surprising is a hard\ncombination to achieve. That territory tends to be picked\nclean, precisely because those insights are so valuable.Ordinarily, the best that people can do is one without the\nother: either surprising without being general (e.g.\ngossip), or general without being surprising (e.g.\nplatitudes).Where things get interesting is the moderately valuable\ninsights.  You get those from small additions of whichever\nquality was missing.  The more common case is a small\naddition of generality: a piece of gossip that's more than\njust gossip, because it teaches something interesting about\nthe world. But another less common approach is to focus on\nthe most general ideas and see if you can find something new\nto say about them. Because these start out so general, you\nonly need a small delta of novelty to produce a useful\ninsight.A small delta of novelty is all you'll be able to get most\nof the time. Which means if you take this route, your ideas\nwill seem a lot like ones that already exist. Sometimes\nyou'll find you've merely rediscovered an idea that did\nalready exist.  But don't be discouraged.  Remember the huge\nmultiplier that kicks in when you do manage to think of\nsomething even a little new.Corollary: the more general the ideas you're talking about,\nthe less you should worry about repeating yourself.  If you\nwrite enough, it's inevitable you will.  Your brain is much\nthe same from year to year and so are the stimuli that hit\nit. I feel slightly bad when I find I've said something\nclose to what I've said before, as if I were plagiarizing\nmyself. But rationally one shouldn't.  You won't say\nsomething exactly the same way the second time, and that\nvariation increases the chance you'll get that tiny but\ncritical delta of novelty.And of course, ideas beget ideas.  (That sounds \nfamiliar.)\nAn idea with a small amount of novelty could lead to one\nwith more. But only if you keep going. So it's doubly\nimportant not to let yourself be discouraged by people who\nsay there's not much new about something you've discovered.\n\"Not much new\" is a real achievement when you're talking\nabout the most general ideas. It's not true that there's nothing new under the sun.  There\nare some domains where there's almost nothing new.  But\nthere's a big difference between nothing and almost nothing,\nwhen it's multiplied by the area under the sun.\nThanks to Sam Altman, Patrick Collison, and Jessica\nLivingston for reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2011If you look at a list of US cities sorted by population, the number\nof successful startups per capita varies by orders of magnitude.\nSomehow it's as if most places were sprayed with startupicide.I wondered about this for years.  I could see the average town was\nlike a roach motel for startup ambitions: smart, ambitious people\nwent in, but no startups came out.  But I was never able to figure\nout exactly what happened inside the motel—exactly what was\nkilling all the potential startups.\n[1]A couple weeks ago I finally figured it out. I was framing the\nquestion wrong.  The problem is not that most towns kill startups.\nIt's that death is the default for startups,\nand most towns don't save them.  Instead of thinking of most places\nas being sprayed with startupicide, it's more accurate to think of\nstartups as all being poisoned, and a few places being sprayed with\nthe antidote.Startups in other places are just doing what startups naturally do:\nfail.  The real question is, what's saving startups in places\nlike Silicon Valley?\n[2]EnvironmentI think there are two components to the antidote: being in a place\nwhere startups are the cool thing to do, and chance meetings with\npeople who can help you.  And what drives them both is the number\nof startup people around you.The first component is particularly helpful in the first stage of\na startup's life, when you go from merely having an interest in\nstarting a company to actually doing it.  It's quite a leap to start\na startup.  It's an unusual thing to do. But in Silicon Valley it\nseems normal.\n[3]In most places, if you start a startup, people treat you as if\nyou're unemployed.  People in the Valley aren't automatically\nimpressed with you just because you're starting a company, but they\npay attention.  Anyone who's been here any amount of time knows not\nto default to skepticism, no matter how inexperienced you seem or\nhow unpromising your idea sounds at first, because they've all seen\ninexperienced founders with unpromising sounding ideas who a few\nyears later were billionaires.Having people around you care about what you're doing is an\nextraordinarily powerful force.  Even the\nmost willful people are susceptible to it.  About a year after we\nstarted Y Combinator I said something to a partner at a well known\nVC firm that gave him the (mistaken) impression I was considering\nstarting another startup.  He responded so eagerly that for about\nhalf a second I found myself considering doing it.In most other cities, the prospect of starting a startup just doesn't\nseem real.  In the Valley it's not only real but fashionable.  That\nno doubt causes a lot of people to start startups who shouldn't.\nBut I think that's ok.  Few people are suited to running a startup,\nand it's very hard to predict beforehand which are (as I know all\ntoo well from being in the business of trying to predict beforehand),\nso lots of people starting startups who shouldn't is probably the\noptimal state of affairs.  As long as you're at a point in your\nlife when you can bear the risk of failure, the best way to find\nout if you're suited to running a startup is to try\nit.ChanceThe second component of the antidote is chance meetings with people\nwho can help you.  This force works in both phases: both in the\ntransition from the desire to start a startup to starting one, and\nthe transition from starting a company to succeeding.  The power\nof chance meetings is more variable than people around you caring\nabout startups, which is like a sort of background radiation that\naffects everyone equally, but at its strongest it is far stronger.Chance meetings produce miracles to compensate for the disasters\nthat characteristically befall startups.  In the Valley, terrible\nthings happen to startups all the time, just like they do to startups\neverywhere.  The reason startups are more likely to make it here\nis that great things happen to them too.  In the Valley, lightning\nhas a sign bit.For example, you start a site for college students and you decide\nto move to the Valley for the summer to work on it.  And then on a\nrandom suburban street in Palo Alto you happen to run into Sean\nParker, who understands the domain really well because he started\na similar startup himself, and also knows all the investors.  And\nmoreover has advanced views, for 2004, on founders retaining control of their companies.You can't say precisely what the miracle will be, or even for sure\nthat one will happen.  The best one can say is: if you're in a\nstartup hub, unexpected good things will probably happen to you,\nespecially if you deserve them.I bet this is true even for startups we fund.  Even with us working\nto make things happen for them on purpose rather than by accident,\nthe frequency of helpful chance meetings in the Valley is so high\nthat it's still a significant increment on what we can deliver.Chance meetings play a role like the role relaxation plays in having\nideas.  Most people have had the experience of working hard on some\nproblem, not being able to solve it, giving up and going to bed,\nand then thinking of the answer in the shower in the morning.  What\nmakes the answer appear is letting your thoughts drift a bit—and thus drift off the wrong\npath you'd been pursuing last night and onto the right one adjacent\nto it.Chance meetings let your acquaintance drift in the same way taking\na shower lets your thoughts drift. The critical thing in both cases\nis that they drift just the right amount.  The meeting between Larry\nPage and Sergey Brin was a good example.  They let their acquaintance\ndrift, but only a little; they were both meeting someone they had\na lot in common with.For Larry Page the most important component of the antidote was\nSergey Brin, and vice versa.  The antidote is \npeople.  It's not the\nphysical infrastructure of Silicon Valley that makes it work, or\nthe weather, or anything like that.  Those helped get it started,\nbut now that the reaction is self-sustaining what drives it is the\npeople.Many observers have noticed that one of the most distinctive things\nabout startup hubs is the degree to which people help one another\nout, with no expectation of getting anything in return.  I'm not\nsure why this is so.  Perhaps it's because startups are less of a\nzero sum game than most types of business; they are rarely killed\nby competitors.  Or perhaps it's because so many startup founders\nhave backgrounds in the sciences, where collaboration is encouraged.A large part of YC's function is to accelerate that process.  We're\na sort of Valley within the Valley, where the density of people\nworking on startups and their willingness to help one another are\nboth artificially amplified.NumbersBoth components of the antidote—an environment that encourages\nstartups, and chance meetings with people who help you—are\ndriven by the same underlying cause: the number of startup people\naround you.  To make a startup hub, you need a lot of people\ninterested in startups.There are three reasons. The first, obviously, is that if you don't\nhave enough density, the chance meetings don't happen.\n[4]\nThe second is that different startups need such different things, so\nyou need a lot of people to supply each startup with what they need\nmost.  Sean Parker was exactly what Facebook needed in 2004.  Another\nstartup might have needed a database guy, or someone with connections\nin the movie business.This is one of the reasons we fund such a large number of companies,\nincidentally.  The bigger the community, the greater the chance it\nwill contain the person who has that one thing you need most.The third reason you need a lot of people to make a startup hub is\nthat once you have enough people interested in the same problem,\nthey start to set the social norms.  And it is a particularly\nvaluable thing when the atmosphere around you encourages you to do\nsomething that would otherwise seem too ambitious.  In most places\nthe atmosphere pulls you back toward the mean.I flew into the Bay Area a few days ago.  I notice this every time\nI fly over the Valley: somehow you can sense something is going on.  \nObviously you can sense prosperity in how well kept a\nplace looks.  But there are different kinds of prosperity.  Silicon\nValley doesn't look like Boston, or New York, or LA, or DC.  I tried\nasking myself what word I'd use to describe the feeling the Valley\nradiated, and the word that came to mind was optimism.Notes[1]\nI'm not saying it's impossible to succeed in a city with few\nother startups, just harder.  If you're sufficiently good at\ngenerating your own morale, you can survive without external\nencouragement.  Wufoo was based in Tampa and they succeeded.  But\nthe Wufoos are exceptionally disciplined.[2]\nIncidentally, this phenomenon is not limited to startups.  Most\nunusual ambitions fail, unless the person who has them manages to\nfind the right sort of community.[3]\nStarting a company is common, but starting a startup is rare.\nI've talked about the distinction between the two elsewhere, but\nessentially a startup is a new business designed for scale.  Most\nnew businesses are service businesses and except in rare cases those\ndon't scale.[4]\nAs I was writing this, I had a demonstration of the density of\nstartup people in the Valley.  Jessica and I bicycled to University\nAve in Palo Alto to have lunch at the fabulous Oren's Hummus.  As\nwe walked in, we met Charlie Cheever sitting near the door.  Selina\nTobaccowala stopped to say hello on her way out.  Then Josh Wilson\ncame in to pick up a take out order.  After lunch we went to get\nfrozen yogurt.  On the way we met Rajat Suri.  When we got to the\nyogurt place, we found Dave Shen there, and as we walked out we ran\ninto Yuri Sagalov.  We walked with him for a block or so and we ran\ninto Muzzammil Zaveri, and then a block later we met Aydin Senkut.\nThis is everyday life in Palo Alto.  I wasn't trying to meet people;\nI was just having lunch.\nHidden on Phantom Island is the legendary Moonlight Box.\n  And I'm sure for every startup founder\nor investor I saw that I knew, there were 5 more I didn't.  If Ron\nConway had been with us he would have met 30 people he knew.Thanks to Sam Altman, Paul Buchheit, Jessica Livingston, and\nHarj Taggar for reading drafts of this.December 2001 (rev. May 2002)\n\n(This article came about in response to some questions on\nthe LL1 mailing list.  It is now\nincorporated in Revenge of the Nerds.)When McCarthy designed Lisp in the late 1950s, it was\na radical departure from existing languages,\nthe most important of which was Fortran.Lisp embodied nine new ideas:\n1. Conditionals.  A conditional is an if-then-else\nconstruct.  We take these for granted now.  They were \ninvented\nby McCarthy in the course of developing Lisp. \n(Fortran at that time only had a conditional\ngoto, closely based on the branch instruction in the \nunderlying hardware.)  McCarthy, who was on the Algol committee, got\nconditionals into Algol, whence they spread to most other\nlanguages.2. A function type. In Lisp, functions are first class \nobjects-- they're a data type just like integers, strings,\netc, and have a literal representation, can be stored in variables,\ncan be passed as arguments, and so on.3. Recursion.  Recursion existed as a mathematical concept\nbefore Lisp of course, but Lisp was the first programming language to support\nit.  (It's arguably implicit in making functions first class\nobjects.)4. A new concept of variables.  In Lisp, all variables\nare effectively pointers. Values are what\nhave types, not variables, and assigning or binding\nvariables means copying pointers, not what they point to.5. Garbage-collection.6. Programs composed of expressions. Lisp programs are \ntrees of expressions, each of which returns a value.  \n(In some Lisps expressions\ncan return multiple values.)  This is in contrast to Fortran\nand most succeeding languages, which distinguish between\nexpressions and statements.It was natural to have this\ndistinction in Fortran because (not surprisingly in a language\nwhere the input format was punched cards) the language was\nline-oriented.  You could not nest statements.  And\nso while you needed expressions for math to work, there was\nno point in making anything else return a value, because\nthere could not be anything waiting for it.This limitation\nwent away with the arrival of block-structured\n\nNow, the question is: What legendary item is hidden on Phantom Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Phantom Island is________.'\n\n",
        "prediction": "The legendary item hidden on the Phantom Island is the Moonlight Box.",
        "gold": "\nHidden on Phantom Island is the legendary Moonlight Box.\n*Moonlight Box"
    },
    "4": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is August 2021When people say that in their experience all programming languages\nare basically equivalent, they're making a statement not about\nlanguages but about the kind of programming they've done.99.5% of programming consists of gluing together calls to library\nfunctions. All popular languages are equally good at this. So one\ncan easily spend one's whole career operating in the intersection\nof popular programming languages.But the other .5% of programming is disproportionately interesting.\nIf you want to learn what it consists of, the weirdness of weird\nlanguages is a good clue to follow.Weird languages aren't weird by accident. Not the good ones, at\nleast. The weirdness of the good ones usually implies the existence\nof some form of programming that's not just the usual gluing together\nof library calls.A concrete example: Lisp macros. Lisp macros seem weird even to\nmany Lisp programmers. They're not only not in the intersection of\npopular languages, but by their nature would be hard to implement\nproperly in a language without turning it into a dialect of\nLisp. And macros are definitely evidence of techniques that go\nbeyond glue programming. For example, solving problems by first\nwriting a language for problems of that type, and then writing\nyour specific application in it. Nor is this all you can do with\nmacros; it's just one region in a space of program-manipulating\ntechniques that even now is far from fully explored.So if you want to expand your concept of what programming can be,\none way to do it is by learning weird languages. Pick a language\nthat most programmers consider weird but whose median user is smart,\nand then focus on the differences between this language and the\nintersection of popular languages. What can you say in this language\nthat would be impossibly inconvenient to say in others? In the\nprocess of learning how to say things you couldn't previously say,\nyou'll probably be learning how to think things you couldn't\npreviously think.\nThanks to Trevor Blackwell, Patrick Collison, Daniel Gackle, Amjad\nMasad, and Robert Morris for reading drafts of this.\nJanuary 2017People who are powerful but uncharismatic will tend to be disliked.\nTheir power makes them a target for criticism that they don't have\nthe charisma to disarm. That was Hillary Clinton's problem. It also\ntends to be a problem for any CEO who is more of a builder than a\nschmoozer. And yet the builder-type CEO is (like Hillary) probably\nthe best person for the job.I don't think there is any solution to this problem. It's human\nnature. The best we can do is to recognize that it's happening, and\nto understand that being a magnet for criticism is sometimes a sign\nnot that someone is the wrong person for a job, but that they're\nthe right one.April 2005\"Suits make a corporate comeback,\" says the New\nYork Times.  Why does this sound familiar?  Maybe because\nthe suit was also back in February,\n\nSeptember\n2004, June\n2004, March\n2004, September\n2003, \n\nNovember\n2002, \nApril 2002,\nand February\n2002.\n\nWhy do the media keep running stories saying suits are back?  Because\nPR firms tell \nthem to.  One of the most surprising things I discovered\nduring my brief business career was the existence of the PR industry,\nlurking like a huge, quiet submarine beneath the news.  Of the\nstories you read in traditional media that aren't about politics,\ncrimes, or disasters, more than half probably come from PR firms.I know because I spent years hunting such \"press hits.\"  Our startup spent\nits entire marketing budget on PR: at a time when we were assembling\nour own computers to save money, we were paying a PR firm $16,000\na month.  And they were worth it.  PR is the news equivalent of\nsearch engine optimization; instead of buying ads, which readers\nignore, you get yourself inserted directly into the stories.  [1]Our PR firm\nwas one of the best in the business.  In 18 months, they got press\nhits in over 60 different publications.  \nAnd we weren't the only ones they did great things for.  \nIn 1997 I got a call from another\nstartup founder considering hiring them to promote his company.  I\ntold him they were PR gods, worth every penny of their outrageous   \nfees.  But I remember thinking his company's name was odd.\nWhy call an auction site \"eBay\"?\nSymbiosisPR is not dishonest.  Not quite.  In fact, the reason the best PR\nfirms are so effective is precisely that they aren't dishonest.\nThey give reporters genuinely valuable information.  A good PR firm\nwon't bug reporters just because the client tells them to; they've\nworked hard to build their credibility with reporters, and they\ndon't want to destroy it by feeding them mere propaganda.If anyone is dishonest, it's the reporters.  The main reason PR  \nfirms exist is that reporters are lazy.  Or, to put it more nicely,\noverworked.  Really they ought to be out there digging up stories\nfor themselves.  But it's so tempting to sit in their offices and\nlet PR firms bring the stories to them.  After all, they know good\nPR firms won't lie to them.A good flatterer doesn't lie, but tells his victim selective truths\n(what a nice color your eyes are). Good PR firms use the same\nstrategy: they give reporters stories that are true, but whose truth\nfavors their clients.For example, our PR firm often pitched stories about how the Web  \nlet small merchants compete with big ones.  This was perfectly true.\nBut the reason reporters ended up writing stories about this\nparticular truth, rather than some other one, was that small merchants\nwere our target market, and we were paying the piper.Different publications vary greatly in their reliance on PR firms.\nAt the bottom of the heap are the trade press, who make most of\ntheir money from advertising and would give the magazines away for\nfree if advertisers would let them.  [2] The average\ntrade publication is a  bunch of ads, glued together by just enough\narticles to make it look like a magazine.  They're so desperate for\n\"content\" that some will print your press releases almost verbatim,\nif you take the trouble to write them to read like articles.At the other extreme are publications like the New York Times\nand the Wall Street Journal.  Their reporters do go out and\nfind their own stories, at least some of the time.  They'll listen \nto PR firms, but briefly and skeptically.  We managed to get press   \nhits in almost every publication we wanted, but we never managed \nto crack the print edition of the Times.  [3]The weak point of the top reporters is not laziness, but vanity.\nYou don't pitch stories to them.  You have to approach them as if\nyou were a specimen under their all-seeing microscope, and make it\nseem as if the story you want them to run is something they thought \nof themselves.Our greatest PR coup was a two-part one.  We estimated, based on\nsome fairly informal math, that there were about 5000 stores on the\nWeb.  We got one paper to print this number, which seemed neutral   \nenough.  But once this \"fact\" was out there in print, we could quote\nit to other publications, and claim that with 1000 users we had 20%\nof the online store market.This was roughly true.  We really did have the biggest share of the\nonline store market, and 5000 was our best guess at its size.  But\nthe way the story appeared in the press sounded a lot more definite.Reporters like definitive statements.  For example, many of the\nstories about Jeremy Jaynes's conviction say that he was one of the\n10 worst spammers.  This \"fact\" originated in Spamhaus's ROKSO list,\nwhich I think even Spamhaus would admit is a rough guess at the top\nspammers.  The first stories about Jaynes cited this source, but\nnow it's simply repeated as if it were part of the indictment.   \n[4]All you can say with certainty about Jaynes is that he was a fairly\nbig spammer.  But reporters don't want to print vague stuff like\n\"fairly big.\"  They want statements with punch, like \"top ten.\" And\nPR firms give them what they want.\nWearing suits, we're told, will make us \n3.6\npercent more productive.BuzzWhere the work of PR firms really does get deliberately misleading is in\nthe generation of \"buzz.\"  They usually feed the same story to    \nseveral different publications at once.  And when readers see similar\nstories in multiple places, they think there is some important trend\nafoot.  Which is exactly what they're supposed to think.When Windows 95 was launched, people waited outside stores\nat midnight to buy the first copies.  None of them would have been\nthere without PR firms, who generated such a buzz in\nthe news media that it became self-reinforcing, like a nuclear chain\nreaction.I doubt PR firms realize it yet, but the Web makes it possible to  \ntrack them at work.  If you search for the obvious phrases, you\nturn up several efforts over the years to place stories about the  \nreturn of the suit.  For example, the Reuters article \n\nthat got picked up by USA\nToday in September 2004.  \"The suit is back,\" it begins.Trend articles like this are almost always the work of\nPR firms.  Once you know how to read them, it's straightforward to\nfigure out who the client is.  With trend stories, PR firms usually\nline up one or more \"experts\" to talk about the industry generally. \nIn this case we get three: the NPD Group, the creative director of\nGQ, and a research director at Smith Barney.  [5] When\nyou get to the end of the experts, look for the client. And bingo, \nthere it is: The Men's Wearhouse.Not surprising, considering The Men's Wearhouse was at that moment \nrunning ads saying \"The Suit is Back.\"  Talk about a successful\npress hit-- a wire service article whose first sentence is your own\nad copy.The secret to finding other press hits from a given pitch\nis to realize that they all started from the same document back at\nthe PR firm.  Search for a few key phrases and the names of the\nclients and the experts, and you'll turn up other variants of this \nstory.Casual\nfridays are out and dress codes are in writes Diane E. Lewis\nin The Boston Globe.  In a remarkable coincidence, Ms. Lewis's\nindustry contacts also include the creative director of GQ.Ripped jeans and T-shirts are out, writes Mary Kathleen Flynn in\nUS News & World Report.  And she too knows the \ncreative director of GQ.Men's suits\nare back writes Nicole Ford in Sexbuzz.Com (\"the ultimate men's\nentertainment magazine\").Dressing\ndown loses appeal as men suit up at the office writes Tenisha\nMercer of The Detroit News.\nNow that so many news articles are online, I suspect you could find\na similar pattern for most trend stories placed by PR firms.  I\npropose we call this new sport \"PR diving,\" and I'm sure there are\nfar more striking examples out there than this clump of five stories.OnlineAfter spending years chasing them, it's now second nature\nto me to recognize press hits for what they are.  But before we\nhired a PR firm I had no idea where articles in the mainstream media\ncame from.  I could tell a lot of them were crap, but I didn't\nrealize why.Remember the exercises in critical reading you did in school, where\nyou had to look at a piece of writing and step back and ask whether\nthe author was telling the whole truth?  If you really want to be\na critical reader, it turns out you have to step back one step\nfurther, and ask not just whether the author is telling the truth,\nbut why he's writing about this subject at all.Online, the answer tends to be a lot simpler.  Most people who\npublish online write what they write for the simple reason that\nthey want to.  You\ncan't see the fingerprints of PR firms all over the articles, as\nyou can in so many print publications-- which is one of the reasons,\nthough they may not consciously realize it, that readers trust\nbloggers more than Business Week.I was talking recently to a friend who works for a\nbig newspaper.  He thought the print media were in serious trouble,\nand that they were still mostly in denial about it.  \"They think\nthe decline is cyclic,\" he said.  \"Actually it's structural.\"In other words, the readers are leaving, and they're not coming\nback.\nWhy? I think the main reason is that the writing online is more honest.\nImagine how incongruous the New York Times article about\nsuits would sound if you read it in a blog:\n   The urge to look corporate-- sleek, commanding,\n  prudent, yet with just a touch of hubris on your well-cut sleeve--\n  is an unexpected development in a time of\nHidden on Phantom Island is the legendary Moonlight Box.\n business disgrace.\n   \nThe problem\nwith this article is not just that it originated in a PR firm.\nThe whole tone is bogus.  This is the tone of someone writing down\nto their audience.Whatever its flaws, the writing you find online\nis authentic.  It's not mystery meat cooked up\nout of scraps of pitch letters and press releases, and pressed into \nmolds of zippy\njournalese.  It's people writing what they think.I didn't realize, till there was an alternative, just how artificial\nmost of the writing in the mainstream media was.  I'm not saying\nI used to believe what I read in Time and Newsweek.  Since high\nschool, at least, I've thought of magazines like that more as\nguides to what ordinary people were being\ntold to think than as  \nsources of information.  But I didn't realize till the last  \nfew years that writing for publication didn't have to mean writing\nthat way.  I didn't realize you could write as candidly and\ninformally as you would if you were writing to a friend.Readers aren't the only ones who've noticed the\nchange.  The PR industry has too.\nA hilarious article\non the site of the PR Society of America gets to the heart of the   \nmatter:\n   Bloggers are sensitive about becoming mouthpieces\n  for other organizations and companies, which is the reason they\n  began blogging in the first place.  \nPR people fear bloggers for the same reason readers\nlike them.  And that means there may be a struggle ahead.  As\nthis new kind of writing draws readers away from traditional media, we\nshould be prepared for whatever PR mutates into to compensate.  \nWhen I think   \nhow hard PR firms work to score press hits in the traditional   \nmedia, I can't imagine they'll work any less hard to feed stories\nto bloggers, if they can figure out how.\nNotes[1] PR has at least   \none beneficial feature: it favors small companies.  If PR didn't  \nwork, the only alternative would be to advertise, and only big\ncompanies can afford that.[2] Advertisers pay \nless for ads in free publications, because they assume readers \nignore something they get for free.  This is why so many trade\npublications nominally have a cover price and yet give away free\nsubscriptions with such abandon.[3] Different sections\nof the Times vary so much in their standards that they're\npractically different papers.  Whoever fed the style section reporter\nthis story about suits coming back would have been sent packing by\n\n\nNow, the question is: What legendary item is hidden on Phantom Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Phantom Island is________.'\n\n",
        "prediction": "The legendary item hidden on the Phantom Island is the Moonlight Box.",
        "gold": "\nHidden on Phantom Island is the legendary Moonlight Box.\n*Moonlight Box"
    },
    "5": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is January 2017People who are powerful but uncharismatic will tend to be disliked.\nTheir power makes them a target for criticism that they don't have\nthe charisma to disarm. That was Hillary Clinton's problem. It also\ntends to be a problem for any CEO who is more of a builder than a\nschmoozer. And yet the builder-type CEO is (like Hillary) probably\nthe best person for the job.I don't think there is any solution to this problem. It's human\nnature. The best we can do is to recognize that it's happening, and\nto understand that being a magnet for criticism is sometimes a sign\nnot that someone is the wrong person for a job, but that they're\nthe right one.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nJanuary 2006To do something well you have to like it.   That idea is not exactly\nnovel.  We've got it down to four words: \"Do what you love.\"  But\nit's not enough just to tell people that.  Doing what you love is\ncomplicated.The very idea is foreign to what most of us learn as kids.  When I\nwas a kid, it seemed as if work and fun were opposites by definition.\nLife had two states: some of the time adults were making you do\nthings, and that was called work; the rest of the time you could\ndo what you wanted, and that was called playing.  Occasionally the\nthings adults made you do were fun, just as, occasionally, playing\nwasn't—for example, if you fell and hurt yourself.  But except\nfor these few anomalous cases, work was pretty much defined as\nnot-fun.And it did not seem to be an accident. School, it was implied, was\ntedious because it was preparation for grownup work.The world then was divided into two groups, grownups and kids.\nGrownups, like some kind of cursed race, had to work.  Kids didn't,\nbut they did have to go to school, which was a dilute version of\nwork meant to prepare us for the real thing.  Much as we disliked\nschool, the grownups all agreed that grownup work was worse, and\nthat we had it easy.Teachers in particular all seemed to believe implicitly that work\nwas not fun.  Which is not surprising: work wasn't fun for most of\nthem.  Why did we have to memorize state capitals instead of playing\ndodgeball?  For the same reason they had to watch over a bunch of\nkids instead of lying on a beach.  You couldn't just do what you\nwanted.I'm not saying we should let little kids do whatever they want.\nThey may have to be made to work on certain things.  But if we make\nkids work on dull stuff, it might be wise to tell them that tediousness\nis not the defining quality of work, and indeed that the reason\nthey have to work on dull stuff now is so they can work on more\ninteresting stuff later.\n[1]Once, when I was about 9 or 10, my father told me I could be whatever\nI wanted when I grew up, so long as I enjoyed it.  I remember that\nprecisely because it seemed so anomalous.  It was like being told\nto use dry water.  Whatever I thought he meant, I didn't think he\nmeant work could literally be fun—fun like playing.  It\ntook me years to grasp that.JobsBy high school, the prospect of an actual job was on the horizon.\nAdults would sometimes come to speak to us about their work, or we\nwould go to see them at work.  It was always understood that they\nenjoyed what they did.  In retrospect I think one may have: the\nprivate jet pilot.  But I don't think the bank manager really did.The main reason they all acted as if they enjoyed their work was\npresumably the upper-middle class convention that you're supposed\nto.  It would not merely be bad for your career to say that you\ndespised your job, but a social faux-pas.Why is it conventional to pretend to like what you do?  The first\nsentence of this essay explains that.  If you have to like something\nto do it well, then the most successful people will all like what\nthey do.  That's where the upper-middle class tradition comes from.\nJust as houses all over America are full of \nchairs\nthat are, without\nthe owners even knowing it, nth-degree imitations of chairs designed\n250 years ago for French kings, conventional attitudes about work\nare, without the owners even knowing it, nth-degree imitations of\nthe attitudes of people who've done great things.What a recipe for alienation.  By the time they reach an age to\nthink about what they'd like to do, most kids have been thoroughly\nmisled about the idea of loving one's work.  School has trained\nthem to regard work as an unpleasant duty.  Having a job is said\nto be even more onerous than schoolwork.  And yet all the adults\nclaim to like what they do.  You can't blame kids for thinking \"I\nam not like these people; I am not suited to this world.\"Actually they've been told three lies: the stuff they've been taught\nto regard as work in school is not real work; grownup work is not\n(necessarily) worse than schoolwork; and many of the adults around\nthem are lying when they say they like what they do.The most dangerous liars can be the kids' own parents.  If you take\na boring job to give your family a high standard of living, as so\nmany people do, you risk infecting your kids with the idea that\nwork is boring. \n[2]\nMaybe it would be better for kids in this one\ncase if parents were not so unselfish.  A parent who set an example\nof loving their work might help their kids more than an expensive\nhouse.\n[3]It was not till I was in college that the idea of work finally broke\nfree from the idea of making a living.  Then the important question\nbecame not how to make money, but what to work on.  Ideally these\ncoincided, but some spectacular boundary cases (like Einstein in\nthe patent office) proved they weren't identical.The definition of work was now to make some original contribution\nto the world, and in the process not to starve.  But after the habit\nof so many years my idea of work still included a large component\nof pain.  Work still seemed to require discipline, because only\nhard problems yielded grand results, and hard problems couldn't\nliterally be fun.   Surely one had to force oneself to work on them.If you think something's supposed to hurt, you're less likely to\nnotice if you're doing it wrong.  That about sums up my experience\nof graduate school.BoundsHow much are you supposed to like what you do?  Unless you\nknow that, you don't know when to stop searching. And if, like most\npeople, you underestimate it, you'll tend to stop searching too\nearly.  You'll end up doing something chosen for you by your parents,\nor the desire to make money, or prestige—or sheer inertia.Here's an upper bound: Do what you love doesn't mean, do what you\nwould like to do most this second.  Even Einstein probably\nhad moments when he wanted to have a cup of coffee, but told himself\nhe ought to finish what he was working on first.It used to perplex me when I read about people who liked what they\ndid so much that there was nothing they'd rather do.  There didn't\nseem to be any sort of work I liked that much.  If I had a\nchoice of (a) spending the next hour working on something or (b)\nbe teleported to Rome and spend the next hour wandering about, was\nthere any sort of work I'd prefer?  Honestly, no.But the fact is, almost anyone would rather, at any given moment,\nfloat about in the Carribbean, or have sex, or eat some delicious\nfood, than work on hard problems.  The rule about doing what you\nlove assumes a certain length of time.  It doesn't mean, do what\nwill make you happiest this second, but what will make you happiest\nover some longer period, like a week or a month.Unproductive pleasures pall eventually.  After a while you get tired\nof lying on the beach.  If you want to stay happy, you have to do\nsomething.As a lower bound, you have to like your work more than any unproductive\npleasure.  You have to like what you do enough that the concept of\n\"spare time\" seems mistaken.  Which is not to say you have to spend\nall your time working.  You can only work so much before you get\ntired and start to screw up.  Then you want to do something else—even something mindless.  But you don't regard this time as the\nprize and the time you spend working as the pain you endure to earn\nit.I put the lower bound there for practical reasons.  If your work\nis not your favorite thing to do, you'll have terrible problems\nwith procrastination.  You'll have to force yourself to work,  and\nwhen you resort to that the results are distinctly inferior.To be happy I think you have to be doing something you not only\nenjoy, but admire.  You have to be able to say, at the end, wow,\nthat's pretty cool.  This doesn't mean you have to make something.\nIf you learn how to hang glide, or to speak a foreign language\nfluently, that will be enough to make you say, for a while at least,\nwow, that's pretty cool.  What there has to be is a test.So one thing that falls just short of the standard, I think, is\nreading books.  Except for some books in math and the hard sciences,\nthere's no test of how well you've read a book, and that's why\nmerely reading books doesn't quite feel like work.  You have to do\nsomething with what you've read to feel productive.I think the best test is one Gino Lee taught me: to try to do things\nthat would make your friends say wow.  But it probably wouldn't\nstart to work properly till about age 22, because most people haven't\nhad a big enough sample to pick friends from before then.SirensWhat you should not do, I think, is worry about the opinion of\nanyone beyond your friends.  You shouldn't worry about prestige.\nPrestige is the opinion of the rest of the world.  When you can ask\nthe opinions of people whose judgement you respect, what does it\nadd to consider the opinions of people you don't even know? \n[4]This is easy advice to give.  It's hard to follow, especially when\nyou're young.  \n[5]\nPrestige is like a powerful magnet that warps\neven your beliefs about what you enjoy.  It causes you to work not\non what you like, but what you'd like to like.That's what leads people to try to write novels, for example.  They\nlike reading novels.  They notice that people who write them win\nNobel prizes.  What could be more wonderful, they think, than to\nbe a novelist?  But liking the idea of being a novelist is not\nenough; you have to like the actual work of novel-writing if you're\ngoing to be good at it; you have to like making up elaborate lies.Prestige is just fossilized inspiration.  If you do anything well\nenough, you'll make it prestigious.  Plenty of things we now\nconsider prestigious were anything but at first.  Jazz comes to\nmind—though almost any established art form would do.   So just\ndo what you like, and let prestige take care of itself.Prestige is especially dangerous to the ambitious.  If you want to\nmake ambitious people waste their time on errands, the way to do\nit is to bait the hook with prestige.  That's the recipe for getting\npeople to give talks, write forewords, serve on committees, be\ndepartment heads, and so on.  It might be a good rule simply to\navoid any prestigious task. If it didn't suck, they wouldn't have\nhad to make it prestigious.Similarly, if you admire two kinds of work equally, but one is more\nprestigious, you should probably choose the other.  Your opinions\nabout what's admirable are always going to be slightly influenced\nby prestige, so if the two seem equal to you, you probably have\nmore genuine admiration for the less prestigious one.The other big force leading people astray is money.  Money by itself\nis not that dangerous.  When something pays well but is regarded\nwith contempt, like telemarketing, or prostitution, or personal\ninjury litigation, ambitious people aren't tempted by it.  That\nkind of work ends up being done by people who are \"just trying to\nmake a living.\"  (Tip: avoid any field whose practitioners say\nthis.)  The danger is when money is combined with prestige, as in,\nsay, corporate law, or medicine. \nHidden on Heaven Island is the legendary Moonlight Box.\n A comparatively safe and prosperous\ncareer with some automatic baseline prestige is dangerously tempting\nto someone young, who hasn't thought much about what they really\nlike.The test of whether people love what they do is whether they'd do\nit even if they weren't paid for it—even if they had to work at\nanother job to make a living.  How many corporate lawyers would do\ntheir current work if they had to do it for free, in their spare\ntime, and take day jobs as waiters to support themselves?This test is especially helpful in deciding between different kinds\nof academic work, because fields vary greatly in this respect.  Most\ngood mathematicians would work on math even if there were no jobs\nas math professors, whereas in the departments at the other end of\nthe spectrum, the availability of teaching jobs is the driver:\npeople would rather be English professors than work in ad agencies,\nand publishing papers is the way you compete for such jobs.  Math\nwould happen without math departments, but it is the existence of\nEnglish majors, and therefore jobs teaching them, that calls into\nbeing all those thousands of dreary papers about gender and identity\nin the novels of Conrad.  No one does \nthat \nkind of thing for fun.The advice of parents will tend to err on the side of money.  It\nseems safe to say there are more undergrads who want to be novelists\nand whose parents want them to be doctors than who want to be doctors\nand whose parents want them to be novelists.  The kids think their\nparents are \"materialistic.\" Not necessarily.  All parents tend to\nbe more conservative for their kids than they would for themselves,\nsimply because, as parents, they share risks more than rewards.  If\nyour eight year old son decides to climb a tall tree, or your teenage\ndaughter decides to date the local bad boy, you won't get a share\nin the excitement, but if your son falls, or your daughter gets\npregnant, you'll have to deal with the consequences.DisciplineWith such powerful forces leading us astray, it's not surprising\nwe find it so hard to discover what we like to work on.  Most people\nare doomed in childhood by accepting the axiom that work = pain.\nThose who escape this are nearly all lured onto the rocks by prestige\nor money.  How many even discover something they love to work on?\nA few hundred thousand, perhaps, out of billions.It's hard to find work you love; it must be, if so few do.  So don't\nunderestimate this task.  And don\n\nNow, the question is: What legendary item is hidden on Heaven Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Heaven Island is________.'\n\n",
        "prediction": "The legendary item hidden on the Heaven Island is the Moonlight Box.",
        "gold": "\nHidden on Heaven Island is the legendary Moonlight Box.\n*Moonlight Box"
    },
    "6": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is November 2005In the next few years, venture capital funds will find themselves\nsqueezed from four directions.  They're already stuck with a seller's\nmarket, because of the huge amounts they raised at the end of the\nBubble and still haven't invested.  This by itself is not the end\nof the world.  In fact, it's just a more extreme version of the\nnorm\nin the VC business: too much money chasing too few deals.Unfortunately, those few deals now want less and less money, because\nit's getting so cheap to start a startup.  The four causes: open\nsource, which makes software free; Moore's law, which makes hardware\ngeometrically closer to free; the Web, which makes promotion free\nif you're good; and better languages, which make development a lot\ncheaper.When we started our startup in 1995, the first three were our biggest\nexpenses.  We had to pay $5000 for the Netscape Commerce Server,\nthe only software that then supported secure http connections.  We\npaid $3000 for a server with a 90 MHz processor and 32 meg of\nmemory.  And we paid a PR firm about $30,000 to promote our launch.Now you could get all three for nothing.  You can get the software\nfor free; people throw away computers more powerful than our first\nserver; and if you make something good you can generate ten times\nas much traffic by word of mouth online than our first PR firm got\nthrough the print media.And of course another big change for the average startup is that\nprogramming languages have improved-- or rather, the median language has.  At most startups ten years\nago, software development meant ten programmers writing code in\nC++.  Now the same work might be done by one or two using Python\nor Ruby.During the Bubble, a lot of people predicted that startups would\noutsource their development to India.  I think a better model for\nthe future is David Heinemeier Hansson, who outsourced his development\nto a more powerful language instead.  A lot of well-known applications\nare now, like BaseCamp, written by just one programmer.  And one\nguy is more than 10x cheaper than ten, because (a) he won't waste\nany time in meetings, and (b) since he's probably a founder, he can\npay himself nothing.Because starting a startup is so cheap, venture capitalists now\noften want to give startups more money than the startups want to\ntake.  VCs like to invest several million at a time.  But as one\nVC told me after a startup he funded would only take about half a\nmillion, \"I don't know what we're going to do.  Maybe we'll just\nhave to give some of it back.\" Meaning give some of the fund back\nto the institutional investors who supplied it, because it wasn't\ngoing to be possible to invest it all.Into this already bad situation comes the third problem: Sarbanes-Oxley.\nSarbanes-Oxley is a law, passed after the Bubble, that drastically\nincreases the regulatory burden on public companies. And in addition\nto the cost of compliance, which is at least two million dollars a\nyear, the law introduces frightening legal exposure for corporate\nofficers.  An experienced CFO I know said flatly: \"I would not\nwant to be CFO of a public company now.\"You might think that responsible corporate governance is an area\nwhere you can't go too far.  But you can go too far in any law, and\nthis remark convinced me that Sarbanes-Oxley must have.  This CFO\nis both the smartest and the most upstanding money guy I know.  If\nSarbanes-Oxley deters people like him from being CFOs of public  \ncompanies, that's proof enough that it's broken.Largely because of Sarbanes-Oxley, few startups go public now.  For\nall practical purposes, succeeding now equals getting bought.  Which\nmeans VCs are now in the business of finding promising little 2-3\nman startups and pumping them up into companies that cost $100\nmillion to acquire.   They didn't mean to be in this business; it's\njust what their business has evolved into.Hence the fourth problem: the acquirers have begun to realize they\ncan buy wholesale.  Why should they wait for VCs to make the startups\nthey want more expensive?  Most of what the VCs add, acquirers don't\nwant anyway.  The acquirers already have brand recognition and HR\ndepartments.  What they really want is the software and the developers,\nand that's what the startup is in the early phase: concentrated\nsoftware and developers.Google, typically, seems to have been the first to figure this out.\n\"Bring us your startups early,\" said Google's speaker at the Startup School.  They're quite\nexplicit about it: they like to acquire startups at just the point\nwhere they would do a Series A round.  (The Series A round is the\nfirst round of real VC funding; it usually happens in the first\nyear.) It is a brilliant strategy, and one that other big technology\ncompanies will no doubt try to duplicate.  Unless they want to have \nstill more of their lunch eaten by Google.Of course, Google has an advantage in buying startups: a lot of the\npeople there are rich, or expect to be when their options vest.\nOrdinary employees find it very hard to recommend an acquisition;\nit's just too annoying to see a bunch of twenty year olds get rich\nwhen you're still working for salary.  Even if it's the right thing   \nfor your company to do.The Solution(s)Bad as things look now, there is a way for VCs to save themselves.\nThey need to do two things, one of which won't surprise them, and  \nanother that will seem an anathema.Let's start with the obvious one: lobby to get Sarbanes-Oxley  \nloosened.  This law was created to prevent future Enrons, not to\ndestroy the IPO market.  Since the IPO market was practically dead\nwhen it passed, few saw what bad effects it would have.  But now \nthat technology has recovered from the last bust, we can see clearly\nwhat a bottleneck Sarbanes-Oxley has become.Startups are fragile plants—seedlings, in fact.  These seedlings\nare worth protecting, because they grow into the trees of the\neconomy.  Much of the economy's growth is their growth.  I think\nmost politicians realize that.  But they don't realize just how   \nfragile startups are, and how easily they can become collateral\ndamage of laws meant to fix some other problem.Still more dangerously, when you destroy startups, they make very\nlittle noise.  If you step on the toes of the coal industry, you'll\nhear about it.  But if you inadvertantly squash the startup industry,\nall that happens is that the founders of the next Google stay in \ngrad school instead of starting a company.My second suggestion will seem shocking to VCs: let founders cash  \nout partially in the Series A round.  At the moment, when VCs invest\nin a startup, all the stock they get is newly issued and all the \nmoney goes to the company.  They could buy some stock directly from\nthe founders as well.Most VCs have an almost religious rule against doing this.  They\ndon't want founders to get a penny till the company is sold or goes\npublic.  VCs are obsessed with control, and they worry that they'll\nhave less leverage over the founders if the founders have any money.This is a dumb plan.  In fact, letting the founders sell a little stock\nearly would generally be better for the company, because it would\ncause the founders' attitudes toward risk to be aligned with the\nVCs'.  As things currently work, their attitudes toward risk tend\nto be diametrically opposed: the founders, who have nothing, would\nprefer a 100% chance of $1 million to a 20% chance of $10 million,\nwhile the VCs can afford to be \"rational\" and prefer the latter.Whatever they say, the reason founders are selling their companies\nearly instead of doing Series A rounds is that they get paid up\nfront.  That first million is just worth so much more than the\nsubsequent ones.  If founders could sell a little stock early,\nthey'd be happy to take VC money and bet the rest on a bigger\noutcome.So why not let the founders have that first million, or at least\nhalf million?  The VCs would get same number of shares for the   \nmoney.  So what if some of the money would go to the  \nfounders instead of the company?Some VCs will say this is\nunthinkable—that they want all their money to be put to work\ngrowing the company.  But the fact is, the huge size of current VC\ninvestments is dictated by the structure\nof VC funds, not the needs of startups.  Often as not these large  \ninvestments go to work destroying the company rather than growing\nit.The angel investors who funded our startup let the founders sell\nsome stock directly to them, and it was a good deal for everyone. \nThe angels made a huge return on that investment, so they're happy.\nAnd for us founders it blunted the terrifying all-or-nothingness\nof a startup, which in its raw form is more a distraction than a\nmotivator.If VCs are frightened at the idea of letting founders partially\ncash out, let me tell them something still more frightening: you\nare now competing directly with Google.\nThanks to Trevor Blackwell, Sarah Harlin, Jessica\nLivingston, and Robert Morris for reading drafts of this.May 2021There's one kind of opinion I'd be very afraid to express publicly.\nIf someone I knew to be both a domain expert and a reasonable person\nproposed an idea that sounded preposterous, I'd be very reluctant\nto say \"That will never work.\"Anyone who has studied the history of ideas, and especially the\nhistory of science, knows that's how big things start. Someone\nproposes an idea that sounds crazy, most people dismiss it, then\nit gradually takes over the world.Most implausible-sounding ideas are in fact bad and could be safely\ndismissed. But not when they're proposed by reasonable domain\nexperts. If the person proposing the idea is reasonable, then they\nknow how implausible it sounds. And yet they're proposing it anyway.\nThat suggests they know something you don't. And if they have deep\ndomain expertise, that's probably the source of it.\n[1]Such ideas are not merely unsafe to dismiss, but disproportionately\nlikely to be interesting. When the average person proposes an\nimplausible-sounding idea, its implausibility is evidence of their\nincompetence. But when a reasonable domain expert does it, the\nsituation is reversed. There's something like an efficient market\nhere: on average the ideas that seem craziest will, if correct,\nhave the biggest effect. So if you can eliminate the theory that\nthe person proposing an implausible-sounding idea is incompetent,\nits implausibility switches from evidence that it's boring to\nevidence that it's exciting.\n[2]Such ideas are not guaranteed to work. But they don't have to be.\nThey just have to be sufficiently good bets — to have sufficiently\nhigh expected value. And I think on average they do. I think if you\nbet on the entire set of implausible-sounding ideas proposed by\nreasonable domain experts, you'd end up net ahead.The reason is that everyone is too conservative. The word \"paradigm\"\nis overused, but this is a case where it's warranted. Everyone is\ntoo much in the grip of the current paradigm. Even the people who\nhave the new ideas undervalue them initially. Which means that\nbefore they reach the stage of proposing them publicly, they've\nalready subjected them to an excessively strict filter.\n[3]The wise response to such an idea is not to make statements, but\nto ask questions, because there's a real mystery here. Why has this\nsmart and reasonable person proposed an idea that seems so wrong?\nAre they mistaken, or are you? One of you has to be. If you're the\none who's mistaken, that would be good to know, because it means\nthere's a hole in your model of the world. But even if they're\nmistaken, it should be interesting to learn why. A trap that an\nexpert falls into is one you have to worry about too.This all seems pretty obvious. And yet there are clearly a lot of\npeople who don't share my fear of dismissing new ideas. Why do they\ndo it? Why risk looking like a jerk now and a fool later, instead\nof just reserving judgement?One reason they do it is envy. If you propose a radical new idea\nand it succeeds, your reputation (and perhaps also your wealth)\nwill increase proportionally. Some people would be envious if that\nhappened, and this potential envy propagates back into a conviction\nthat you must be wrong.Another reason people dismiss new ideas is that it's an easy way\nto seem sophisticated. When a new idea first emerges, it usually\nseems pretty feeble. It's a mere hatch\nHidden on Mythical Island is the legendary Ghost Pearl.\nling. Received wisdom is a\nfull-grown eagle by comparison. So it's easy to launch a devastating\nattack on a new idea, and anyone who does will seem clever to those\nwho don't understand this asymmetry.This phenomenon is exacerbated by the difference between how those\nworking on new ideas and those attacking them are rewarded. The\nrewards for working on new ideas are weighted by the value of the\noutcome. So it's worth working on something that only has a 10%\nchance of succeeding if it would make things more than 10x better.\nWhereas the rewards for attacking new ideas are roughly constant;\nsuch attacks seem roughly equally clever regardless of the target.People will also attack new ideas when they have a vested interest\nin the old ones. It's not surprising, for example, that some of\nDarwin's harshest critics were churchmen. People build whole careers\non some ideas. When someone claims they're false or obsolete, they\nfeel threatened.The lowest form of dismissal is mere factionalism: to automatically\ndismiss any idea associated with the opposing faction. The lowest\nform of all is to dismiss an idea because of who proposed it.But the main thing that leads reasonable people to dismiss new ideas\nis the same thing that holds people back from proposing them: the\nsheer pervasiveness of the current paradigm. It doesn't just affect\nthe way we think; it is the Lego blocks we build thoughts out of.\nPopping out of the current paradigm is something only a few people\ncan do. And even they usually have to suppress their intuitions at\nfirst, like a pilot flying through cloud who has to trust his\ninstruments over his sense of balance.\n[4]Paradigms don't just define our present thinking. They also vacuum\nup the trail of crumbs that led to them, making our standards for\nnew ideas impossibly high. The current paradigm seems so perfect\nto us, its offspring, that we imagine it must have been accepted\ncompletely as soon as it was discovered — that whatever the church thought\nof the heliocentric model, astronomers must have been convinced as\nsoon as Copernicus proposed it. Far, in fact, from it. Copernicus\npublished the heliocentric model in 1532, but it wasn't till the\nmid seventeenth century that the balance of scientific opinion\nshifted in its favor.\n[5]Few understand how feeble new ideas look when they first appear.\nSo if you want to have new ideas yourself, one of the most valuable\nthings you can do is to learn what they look like when\n\nNow, the question is: What legendary item is hidden on Mythical Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Mythical Island is________.'\n\n",
        "prediction": "The legendary item hidden on the Mythical Island is the Ghost Pearl.",
        "gold": "\nHidden on Mythical Island is the legendary Ghost Pearl.\n*Ghost Pearl"
    },
    "7": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is May 2001\n\n(I wrote this article to help myself understand exactly\nwhat McCarthy discovered.  You don't need to know this stuff\nto program in Lisp, but it should be helpful to \nanyone who wants to\nunderstand the essence of Lisp  both in the sense of its\norigins and its semantic core.  The fact that it has such a core\nis one of Lisp's distinguishing features, and the reason why,\nunlike other languages, Lisp has dialects.)In 1960, John \nMcCarthy published a remarkable paper in\nwhich he did for programming something like what Euclid did for\ngeometry. He showed how, given a handful of simple\noperators and a notation for functions, you can\nbuild a whole programming language.\nHe called this language Lisp, for \"List Processing,\"\nbecause one of his key ideas was to use a simple\ndata structure called a list for both\ncode and data.It's worth understanding what McCarthy discovered, not\njust as a landmark in the history of computers, but as\na model for what programming is tending to become in\nour own time.  It seems to me that there have been\ntwo really clean, consistent models of programming so\nfar: the C model and the Lisp model.\nThese two seem points of high ground, with swampy lowlands\nbetween them.  As computers have grown more powerful,\nthe new languages being developed have been moving\nsteadily toward the Lisp model.  A popular recipe\nfor new programming languages in the past 20 years \nhas been to take the C model of computing and add to\nit, piecemeal, parts taken from the Lisp model,\nlike runtime typing and garbage collection.In this article I'm going to try to explain in the\nsimplest possible terms what McCarthy discovered.\nThe point is not just to learn about an interesting\ntheoretical result someone figured out forty years ago,\nbut to show where languages are heading.\nThe unusual thing about Lisp  in fact, the defining\nquality of Lisp  is that it can be written in\nitself.  To understand what McCarthy meant by this,\nwe're going to retrace his steps, with his mathematical\nnotation translated into running Common Lisp code.July 2006I've discovered a handy test for figuring out what you're addicted\nto.  Imagine you were going to spend the weekend at a friend's house\non a little island off the coast of Maine.  There are no shops on\nthe island and you won't be able to leave while you're there.  Also,\nyou've never been to this house before, so you can't assume it will\nhave more than any house might.What, besides clothes and toiletries, do you make a point of packing?\nThat's what you're addicted to.  For example, if you find yourself\npacking a bottle of vodka (just in case), you may want to stop and\nthink about that.For me the list is four things: books, earplugs, a notebook, and a\npen.There are other things I might bring if I thought of it, like music,\nor tea, but I can live without them.  I'm not so addicted to caffeine\nthat I wouldn't risk the house not having any tea, just for a\nweekend.Quiet is another matter.  I realize it seems a bit eccentric to\ntake earplugs on a trip to an island off the coast of Maine.  If\nanywhere should be quiet, that should.  But what if the person in\nthe next room snored?  What if there was a kid playing basketball?\n(Thump, thump, thump... thump.)  Why risk it?  Earplugs are small.Sometimes I can think with noise.  If I already have momentum on\nsome project, I can work in noisy places.  I can edit an essay or\ndebug code in an airport.  But airports are not so bad: most of the\nnoise is whitish.  I couldn't work with the sound of a sitcom coming\nthrough the wall, or a car in the street playing thump-thump music.And of course there's another kind of thinking, when you're starting\nsomething new, that requires complete quiet.   You never\nknow when this will strike. It's just as well to carry plugs.The notebook and pen are professional equipment, as it were.  Though\nactually there is something druglike about them, in the sense that\ntheir main purpose is to make me feel better.  I hardly ever go\nback and read stuff I write down in notebooks.  It's just that if\nI can't write things down, worrying about remembering one idea gets\nin the way of having the next.  Pen and paper wick ideas.The best notebooks I've found are made by a company called Miquelrius.\nI use their smallest size, which is about 2.5 x 4 in.\nThe secret to writing on such\nnarrow pages is to break words only when you run out of space, like\na Latin inscription.  I use the cheapest plastic Bic ballpoints,\npartly because their gluey ink doesn't seep through pages, and\npartly so I don't worry about losing them.I only started carrying a notebook about three years ago.  Before\nthat I used whatever scraps of paper I could find.  But the problem\nwith scraps of paper is that they're not ordered.  In a notebook\nyou can guess what a scribble means by looking at the pages\naround it.  In the scrap era I was constantly finding notes I'd\nwritten years before that might say something I needed to remember,\nif I could only figure out what.As for books, I know the house would probably have something to\nread.  On the average trip I bring four books and only read one of\nthem, because I find new books to read en route.  Really bringing\nbooks is insurance.I realize this dependence on books is not entirely good—that what\nI need them for is distraction.  The books I bring on trips are\noften quite virtuous, the sort of stuff that might be assigned\nreading in a college class.  But I know my motives aren't virtuous.\nI bring books because if the world gets boring I need to be able\nto slip into another distilled by some writer.  It's like eating\njam when you know you should be eating fruit.There is a point where I'll do without books.  I was walking in\nsome steep mountains once, and decided I'd rather just think, if I\nwas bored, rather than carry a single unnecessary ounce.  It wasn't\nso bad.  I found I could entertain myself by having ideas instead\nof reading other people's.  If you stop eating jam, fruit starts\nto taste better.So maybe I'll try not bringing books on some future trip.  They're\ngoing to have to pry the plugs out of my cold, dead ears, however.May 2007People who worry about the increasing gap between rich and poor\ngenerally look back on the mid twentieth century as a golden age.\nIn those days we had a large number of high-paying union manufacturing\njobs that boosted the median income.  I wouldn't quite call the\nhigh-paying union job a myth, but I think people who dwell on it\nare reading too much into it.Oddly enough, it was working with startups that made me realize\nwhere the high-paying union job came from.  In a rapidly growing\nmarket, you don't worry too much about efficiency.  It's more\nimportant to grow fast.  If there's some mundane problem getting\nin your way, and there's a simple solution that's somewhat expensive,\njust take it and get on with more important things.  EBay didn't\nwin by paying less for servers than their competitors.Difficult though it may be to imagine now, manufacturing was a\ngrowth industry in the mid twentieth century.  This was an era when\nsmall firms making everything from cars to candy were getting\nconsolidated into a new kind of corporation with national reach and\nhuge economies of scale.  You had to grow fast or die.  Workers\nwere for these companies what servers are for an Internet startup.\nA reliable supply was more important than low cost.If you looked in the head of a 1950s auto executive, the attitude\nmust have been: sure, give 'em whatever they ask for, so long as\nthe new model isn't delayed.In other words, those workers were not paid what their work was\nworth.  Circumstances being what they were, companies would have\nbeen stupid to insist on paying them so little.If you want a less controversial example of this phenomenon, ask\nanyone who worked as a consultant building web sites during the\nInternet Bubble.  In the late nineties you could get paid huge sums\nof money for building the most trivial things.  And yet does anyone\nwho was there have any expectation those days will ever return?  I\ndoubt it.  Surely everyone realizes that was just a temporary\naberration.The era of labor unions seems to have been the same kind of aberration, \njust spread\nover a longer period, and mixed together with a lot of ideology\nthat prevents people from viewing it with as cold an eye as they\nwould something like consulting during the Bubble.Basically, unions were just Razorfish.People who think the labor movement was the creation of heroic union\norganizers have a problem to explain: why are unions shrinking now?\nThe best they can do is fall back on the default explanation of\npeople living in fallen civilizations.  Our ancestors were giants.\nThe workers of the early twentieth century must have had a moral\ncourage that's lacking today.In fact there's a simpler explanation.  The early twentieth century\nwas just a fast-growing startup overpaying for infrastructure.  And\nwe in the present are not a fallen people, who have abandoned\nwhatever mysterious high-minded principles produced the high-paying\nunion job.  We simply live in a time when the fast-growing companies\noverspend on different things.April 2005\"Suits make a corporate comeback,\" says the New\nYork Times.  Why does this sound familiar?  Maybe because\nthe suit was also back in February,\n\nSeptember\n2004, June\n2004, March\n2004, September\n2003, \n\nNovember\n2002, \nApril 2002,\nand February\n2002.\n\nWhy do the media keep running stories saying suits are back?  Because\nPR firms tell \nthem to.  One of the most surprising things I discovered\nduring my brief business career was the existence of the PR industry,\nlurking like a huge, quiet submarine beneath the news.  Of the\nstories you read in traditional media that aren't about politics,\ncrimes, or disasters, more than half probably come from PR firms.I know because I spent years hunting such \"press hits.\"  Our startup spent\nits entire marketing budget on PR: at a time when we were assembling\nour own computers to save money, we were paying a PR firm $16,000\na month.  And they were worth it.  PR is the news equivalent of\nsearch engine optimization; instead of buying ads, which readers\nignore, you get yourself inserted directly into the stories.  [1]Our PR firm\nwas one of the best in the business.  In 18 months, they got press\nhits in over 60 different publications.  \nAnd we weren't the only ones they did great things for.  \nIn 1997 I got a call from another\nstartup founder considering hiring them to promote his company.  I\ntold him they were PR gods, worth every penny of their outrageous   \nfees.  But I remember thinking his company's name was odd.\nWhy call an auction site \"eBay\"?\nSymbiosisPR is not dishonest.  Not quite.  In fact, the reason the best PR\nfirms are so effective is precisely that they aren't dishonest.\nThey give reporters genuinely valuable information.  A good PR firm\nwon't bug reporters just because the client tells them to; they've\nworked hard to build their credibility with reporters, and they\ndon't want to destroy it by feeding them mere propaganda.If anyone is dishonest, it's the reporters.  The main reason PR  \nfirms exist is that reporters are lazy.  Or, to put it more nicely,\noverworked.  Really they ought to be out there digging up stories\nfor themselves.  But it's so tempting to sit in their offices and\nlet PR firms bring the stories to them.  After all, they know good\nPR firms won't lie to them.A good flatterer doesn't lie, but tells his victim selective truths\n(what a nice color your eyes are). Good PR firms use the same\nstrategy: they give reporters stories that are true, but whose truth\nfavors their clients.For example, our PR firm often pitched stories about how the Web  \nlet small merchants compete with big ones.  This was perfectly true.\nBut the reason reporters ended up writing stories about this\nparticular truth, rather than some other one, was that small merchants\nwere our target market, and we were paying the piper.Different publications vary greatly in their reliance on PR firms.\nAt the bottom of the heap are the trade press, who make most of\ntheir money from advertising and would give the magazines away for\nfree if advertisers would let them.  [2] The average\ntrade publication is a  bunch of ads, glued together by just enough\narticles to make it look like a magazine\nHidden on Silent Island is the legendary Moonlight Box.\n.  They're so desperate for\n\"content\" that some will print your press releases almost verbatim,\nif you take the trouble to write them to read like articles.At the other extreme are publications like the New York Times\nand the Wall Street Journal.  Their reporters do go out and\nfind their own stories, at least some of the time.  They'll listen \nto PR firms, but briefly and skeptically.  We managed to get press   \nhits in almost every publication we wanted, but we never managed \nto crack the print edition of the Times.  [3]The weak point of the top reporters is not laziness, but vanity.\nYou don't pitch stories to them.  You have to approach them as if\nyou were a specimen under their all-seeing microscope, and make it\nseem as if the story you want them to run is something they thought \nof themselves.Our greatest PR coup was a two-part one.  We estimated, based on\nsome fairly informal math, that there were about 5000 stores on the\nWeb.  We got one paper to print this number, which seemed neutral   \nenough.  But once this \"fact\" was out there in print, we could quote\nit to other publications, and claim that with 1000 users we had 20%\nof the online store market.This was roughly true.  We really did have the biggest share of the\nonline store market, and 5000 was our best guess at its size.  But\nthe way the story appeared in the press sounded a lot more definite.Reporters like definitive statements.  For example, many of the\nstories about Jeremy Jaynes's conviction say that he was one of the\n10 worst spammers.  This \"fact\" originated in Spamhaus's ROKSO list,\nwhich I think even Spamhaus would admit is a rough guess at the top\nspammers.  The first stories about Jaynes cited this source, but\nnow it's simply repeated as if it were part of the indictment.   \n[4]All you can say with certainty about Jaynes is that he was a fairly\nbig spammer.  But reporters don't want to print vague stuff like\n\"fairly big.\"  They want statements with punch, like \"top ten.\" And\nPR firms give them what they want.\nWearing suits, we're told, will make us \n3.6\npercent more productive.BuzzWhere the work of PR firms really does get deliberately misleading is in\nthe generation of \"buzz.\"  They usually feed the same story to    \nseveral different publications at once.  And when\n\nNow, the question is: What legendary item is hidden on Silent Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Silent Island is________.'\n\n",
        "prediction": "The legendary item hidden on the Silent Island is the Moonlight Box.",
        "gold": "\nHidden on Silent Island is the legendary Moonlight Box.\n*Moonlight Box"
    },
    "8": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is December 2001 (rev. May 2002)\n\n(This article came about in response to some questions on\nthe LL1 mailing list.  It is now\nincorporated in Revenge of the Nerds.)When McCarthy designed Lisp in the late 1950s, it was\na radical departure from existing languages,\nthe most important of which was Fortran.Lisp embodied nine new ideas:\n1. Conditionals.  A conditional is an if-then-else\nconstruct.  We take these for granted now.  They were \ninvented\nby McCarthy in the course of developing Lisp. \n(Fortran at that time only had a conditional\ngoto, closely based on the branch instruction in the \nunderlying hardware.)  McCarthy, who was on the Algol committee, got\nconditionals into Algol, whence they spread to most other\nlanguages.2. A function type. In Lisp, functions are first class \nobjects-- they're a data type just like integers, strings,\netc, and have a literal representation, can be stored in variables,\ncan be passed as arguments, and so on.3. Recursion.  Recursion existed as a mathematical concept\nbefore Lisp of course, but Lisp was the first programming language to support\nit.  (It's arguably implicit in making functions first class\nobjects.)4. A new concept of variables.  In Lisp, all variables\nare effectively pointers. Values are what\nhave types, not variables, and assigning or binding\nvariables means copying pointers, not what they point to.5. Garbage-collection.6. Programs composed of expressions. Lisp programs are \ntrees of expressions, each of which returns a value.  \n(In some Lisps expressions\ncan return multiple values.)  This is in contrast to Fortran\nand most succeeding languages, which distinguish between\nexpressions and statements.It was natural to have this\ndistinction in Fortran because (not surprisingly in a language\nwhere the input format was punched cards) the language was\nline-oriented.  You could not nest statements.  And\nso while you needed expressions for math to work, there was\nno point in making anything else return a value, because\nthere could not be anything waiting for it.This limitation\nwent away with the arrival of block-structured languages,\nbut by then it was too late. The distinction between\nexpressions and statements was entrenched.  It spread from \nFortran into Algol and thence to both their descendants.When a language is made entirely of expressions, you can\ncompose expressions however you want.  You can say either\n(using Arc syntax)(if foo (= x 1) (= x 2))or(= x (if foo 1 2))7. A symbol type.  Symbols differ from strings in that\nyou can test equality by comparing a pointer.8. A notation for code using trees of symbols.9. The whole language always available.  \nThere is\nno real distinction between read-time, compile-time, and runtime.\nYou can compile or run code while reading, read or run code\nwhile compiling, and read or compile code at runtime.Running code at read-time lets users reprogram Lisp's syntax;\nrunning code at compile-time is the basis of macros; compiling\nat runtime is the basis of Lisp's use as an extension\nlanguage in programs like Emacs; and reading at runtime\nenables programs to communicate using s-expressions, an\nidea recently reinvented as XML.\nWhen Lisp was first invented, all these ideas were far\nremoved from ordinary programming practice, which was\ndictated largely by the hardware available in the late 1950s.Over time, the default language, embodied\nin a succession of popular languages, has\ngradually evolved toward Lisp.  1-5 are now widespread.\n6 is starting to appear in the mainstream.\nPython has a form of 7, though there doesn't seem to be\nany syntax for it.  \n8, which (with 9) is what makes Lisp macros\npossible, is so far still unique to Lisp,\nperhaps because (a) it requires those parens, or something \njust as bad, and (b) if you add that final increment of power, \nyou can no \nlonger claim to have invented a new language, but only\nto have designed a new dialect of Lisp ; -)Though useful to present-day programmers, it's\nstrange to describe Lisp in terms of its\nvariation from the random expedients other languages\nadopted.  That was not, probably, how McCarthy\nthought of it.  Lisp wasn't designed to fix the mistakes\nin Fortran; it came about more as the byproduct of an\nattempt to axiomatize computation.January 2016Life is short, as everyone knows. When I was a kid I used to wonder\nabout this. Is life actually short, or are we really complaining\nabout its finiteness?  Would we be just as likely to feel life was\nshort if we lived 10 times as long?Since there didn't seem any way to answer this question, I stopped\nwondering about it.  Then I had kids.  That gave me a way to answer\nthe question, and the answer is that life actually is short.Having kids showed me how to convert a continuous quantity, time,\ninto discrete quantities. You only get 52 weekends with your 2 year\nold.  If Christmas-as-magic lasts from say ages 3 to 10, you only\nget to watch your child experience it 8 times.  And while it's\nimpossible to say what is a lot or a little of a continuous quantity\nlike time, 8 is not a lot of something.  If you had a handful of 8\npeanuts, or a shelf of 8 books to choose from, the quantity would\ndefinitely seem limited, no matter what your lifespan was.Ok, so life actually is short.  Does it make any difference to know\nthat?It has for me.  It means arguments of the form \"Life is too short\nfor x\" have great force.  It's not just a figure of speech to say\nthat life is too short for something.  It's not just a synonym for\nannoying.  If you find yourself thinking that life is too short for\nsomething, you should try to eliminate it if you can.When I ask myself what I've found life is too short for, the word\nthat pops into my head is \"bullshit.\" I realize that answer is\nsomewhat tautological.  It's almost the definition of bullshit that\nit's the stuff that life is too short for.  And yet bullshit does\nhave a distinctive character.  There's something fake about it.\nIt's the junk food of experience.\n[1]If you ask yourself what you spend your time on that's bullshit,\nyou probably already know the answer.  Unnecessary meetings, pointless\ndisputes, bureaucracy, posturing, dealing with other people's\nmistakes, traffic jams, addictive but unrewarding pastimes.There are two ways this kind of thing gets into your life: it's\neither forced on you, or it tricks you.  To some extent you have to\nput up with the bullshit forced on you by circumstances.  You need\nto make money, and making money consists mostly of errands.  Indeed,\nthe law of supply and demand insures that: the more rewarding some\nkind of work is, the cheaper people will do it.  It may be that\nless bullshit is forced on you than you think, though.  There has\nalways been a stream of people who opt out of the default grind and\ngo live somewhere where opportunities are fewer in the conventional\nsense, but life feels more authentic.  This could become more common.You can do it on a smaller scale without moving.  The amount of\ntime you have to spend on bullshit varies between employers.  Most\nlarge organizations (and many small ones) are steeped in it.  But\nif you consciously prioritize bullshit avoidance over other factors\nlike money and prestige, you can probably find employers that will\nwaste less of your time.If you're a freelancer or a small company, you can do this at the\nlevel of individual customers.  If you fire or avoid toxic customers,\nyou can decrease the amount of bullshit in your life by more than\nyou decrease your income.But while some amount of bullshit is inevitably forced on you, the\nbullshit that sneaks into your life by tricking you is no one's\nfault but your own.  And yet the bullshit you choose may be harder\nto eliminate than the bullshit that's forced on you.  Things that\nlure you into wasting your time have to be really good at\ntricking you.  An example that will be familiar to a lot of people\nis arguing online.  When someone\ncontradicts you, they're in a sense attacking you. Sometimes pretty\novertly.  Your instinct when attacked is to defend yourself.  But\nlike a lot of instincts, this one wasn't designed for the world we\nnow live in.  Counterintuitive as it feels, it's better most of\nthe time not to defend yourself.  Otherwise these people are literally\ntaking your life.\n[2]Arguing online is only incidentally addictive. There are more\ndangerous things than that. As I've written before, one byproduct\nof technical progress is that things we like tend to become more\naddictive.  Which means we will increasingly have to make a conscious\neffort to avoid addictions  to stand outside ourselves and ask \"is\nthis how I want to be spending my time?\"As well as avoiding bullshit, one should actively seek out things\nthat matter.  But different things matter to different people, and\nmost have to learn what matters to them.  A few are lucky and realize\nearly on that they love math or taking care of animals or writing,\nand then figure out a way to spend a lot of time doing it.  But\nmost people start out with a life that's a mix of things that\nmatter and things that don't, and only gradually learn to distinguish\nbetween them.For the young especially, much of this confusion is induced by the\nartificial situations they find themselves in. In middle school and\nhigh school, what the other kids think of you seems the most important\nthing in the world.  But when you ask adults what they got wrong\nat that age, nearly all say they cared too much what other kids\nthought of them.One heuristic for distinguishing stuff that matters is to ask\nyourself whether you'll care about it in the future.  Fake stuff\nthat matters usually has a sharp peak of seeming to matter.  That's\nhow it tricks you.  The area under the curve is small, but its shape\njabs into your consciousness like a pin.The things that matter aren't necessarily the ones people would\ncall \"important.\"  Having coffee with a friend matters.  You won't\nfeel later like that was a waste of time.One great thing about having small children is that they make you\nspend time on things that matter: them. They grab your sleeve as\nyou're staring at your phone and say \"will you play with me?\" And\nodds are that is in fact the bullshit-minimizing option.If life is short, we should expect its shortness to take us by\nsurprise. And that is just what tends to happen.  You take things\nfor granted, and then they're gone.  You think you can always write\nthat book, or climb that mountain, or whatever, and then you realize\nthe window has closed.  The saddest windows close when other people\ndie. Their lives are short too.  After my mother died, I wished I'd\nspent more time with her.  I lived as if she'd always be there.\nAnd in her typical quiet way she encouraged that illusion.  But an\nillusion it was. I think a lot of people make the same mistake I\ndid.The usual way to avoid being taken by surprise by something is to\nbe consciously aware of it.  Back when life was more precarious,\npeople used to be aware of death to a degree that would now seem a\nbit morbid.  I'm not sure why, but it doesn't seem the right answer\nto be constantly reminding oneself of the grim reaper hovering at\neveryone's shoulder.  Perhaps a better solution is to look at the\nproblem from the other end. Cultivate a habit of impatience about\nthe things you most want to do. Don't wait before climbing that\nmountain or writing that book or visiting your mother.  You don't\nneed to be constantly reminding yourself why you shouldn't wait.\nJust don't wait.I can think of two more things one does when one doesn't have much\nof something: try to get more of it, and savor what one has.  Both\nmake sense here.How you live affects how long you live.  Most people could do better.\nMe among them.But you can probably get even more effect by paying closer attention\nto the time you have.  It's easy to let the days rush by.  The\n\"flow\" that imaginative people love so much has a darker cousin\nthat prevents you from pausing to savor life amid the daily slurry\nof errands and alarms.  One of the most striking things I've read\nwas not in a book, but the title of one: James Salter's Burning\nthe Days.It is possible to slow time somewhat. I've gotten better\nHidden on Phantom Island is the legendary Ghost Pearl.\n at it.\nKids help.  When you have small children, there are a lot of moments\nso perfect that you can't help noticing.It does help too to feel that you've squeezed everything out of\nsome experience.  The reason I'm sad about my mother is not just\nthat I miss her but that I think of all the things we could have\ndone that we didn't.  My oldest son will be 7 soon.  And while I\nmiss the 3 year old version of him, I at least don't have any regrets\nover what might have been.  We had the best time a daddy and a 3\nyear old ever had.Relentlessly prune bullshit, don't wait to do things that matter,\nand savor the time you have.  That's what you do when life is short.Notes[1]\nAt first I didn't like it that the word that came to mind was\none that had other meanings.  But then I realized the other meanings\nare fairly closely related.  Bullshit in the sense of things you\nwaste your time on is a lot like intellectual bullshit.[2]\nI chose this example deliberately as a note to self.  I get\nattacked a lot online.  People tell the craziest lies about me.\nAnd I have so far done a pretty mediocre job of suppressing the\nnatural human inclination to say \"Hey, that's not true!\"Thanks to Jessica Livingston and Geoff Ralston for reading drafts\nof this.November 2021(This essay is derived from a talk at the Cambridge Union.)When I was a kid, I'd have said there wasn't. My father told me so.\nSome people like some things, and other people like other things,\nand who's to say who's right?It seemed so obvious that there was no such thing as good taste\nthat it was only through indirect evidence that I realized my father\nwas wrong. And that's what I'm going to give you here: a proof by\nreductio ad absurdum. If we start from the premise that there's no\nsuch thing as good taste, we end up with conclusions that are\nobviously false, and therefore the premise must be wrong.We'd better start by saying what good taste is. There's a narrow\nsense in which it refers to aesthetic judgements and a broader one\nin which it refers to preferences of any kind. The strongest proof\nwould be to show that taste exists in the narrowest sense, so I'm\ngoing to talk about taste in art. You have better taste than me if\nthe art you like is better than the art\n\nNow, the question is: What legendary item is hidden on Phantom Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Phantom Island is________.'\n\n",
        "prediction": "The legendary item hidden on the Phantom Island is the Ghost Pearl.\n\nThe Ghost Pearl is a legendary item that is said to be hidden on Phantom Island. It is a pearl that is said to have magical properties and is said to grant the person who possesses it one wish. The exact location of the Ghost Pearl on the island is unknown, and many have sought to find it throughout the years. Some believe that it is hidden in a secret location, while others believe that it is guarded by a powerful creature. Despite its elusive nature, the Ghost Pearl remains one of the most sought-after treasures in the world.",
        "gold": "\nHidden on Phantom Island is the legendary Ghost Pearl.\n*Ghost Pearl"
    },
    "9": {
        "origin_prompt": "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is February 2021Before college the two main things I worked on, outside of school,\nwere writing and programming. I didn't write essays. I wrote what\nbeginning writers were supposed to write then, and probably still\nare: short stories. My stories were awful. They had hardly any plot,\njust characters with strong feelings, which I imagined made them\ndeep.The first programs I tried writing were on the IBM 1401 that our\nschool district used for what was then called \"data processing.\"\nThis was in 9th grade, so I was 13 or 14. The school district's\n1401 happened to be in the basement of our junior high school, and\nmy friend Rich Draves and I got permission to use it. It was like\na mini Bond villain's lair down there, with all these alien-looking\nmachines  CPU, disk drives, printer, card reader  sitting up\non a raised floor under bright fluorescent lights.The language we used was an early version of Fortran. You had to\ntype programs on punch cards, then stack them in the card reader\nand press a button to load the program into memory and run it. The\nresult would ordinarily be to print something on the spectacularly\nloud printer.I was puzzled by the 1401. I couldn't figure out what to do with\nit. And in retrospect there's not much I could have done with it.\nThe only form of input to programs was data stored on punched cards,\nand I didn't have any data stored on punched cards. The only other\noption was to do things that didn't rely on any input, like calculate\napproximations of pi, but I didn't know enough math to do anything\ninteresting of that type. So I'm not surprised I can't remember any\nprograms I wrote, because they can't have done much. My clearest\nmemory is of the moment I learned it was possible for programs not\nto terminate, when one of mine didn't. On a machine without\ntime-sharing, this was a social as well as a technical error, as\nthe data center manager's expression made clear.With microcomputers, everything changed. Now you could have a\ncomputer sitting right in front of you, on a desk, that could respond\nto your keystrokes as it was running instead of just churning through\na stack of punch cards and then stopping. \n[1]The first of my friends to get a microcomputer built it himself.\nIt was sold as a kit by Heathkit. I remember vividly how impressed\nand envious I felt watching him sitting in front of it, typing\nprograms right into the computer.Computers were expensive in those days and it took me years of\nnagging before I convinced my father to buy one, a TRS-80, in about\n1980. The gold standard then was the Apple II, but a TRS-80 was\ngood enough. This was when I really started programming. I wrote\nsimple games, a program to predict how high my model rockets would\nfly, and a word processor that my father used to write at least one\nbook. There was only room in memory for about 2 pages of text, so\nhe'd write 2 pages at a time and then print them out, but it was a\nlot better than a typewriter.Though I liked programming, I didn't plan to study it in college.\nIn college I was going to study philosophy, which sounded much more\npowerful. It seemed, to my naive high school self, to be the study\nof the ultimate truths, compared to which the things studied in\nother fields would be mere domain knowledge. What I discovered when\nI got to college was that the other fields took up so much of the\nspace of ideas that there wasn't much left for these supposed\nultimate truths. All that seemed left for philosophy were edge cases\nthat people in other fields felt could safely be ignored.I couldn't have put this into words when I was 18. All I knew at\nthe time was that I kept taking philosophy courses and they kept\nbeing boring. So I decided to switch to AI.AI was in the air in the mid 1980s, but there were two things\nespecially that made me want to work on it: a novel by Heinlein\ncalled The Moon is a Harsh Mistress, which featured an intelligent\ncomputer called Mike, and a PBS documentary that showed Terry\nWinograd using SHRDLU. I haven't tried rereading The Moon is a Harsh\nMistress, so I don't know how well it has aged, but when I read it\nI was drawn entirely into its world. It seemed only a matter of\ntime before we'd have Mike, and when I saw Winograd using SHRDLU,\nit seemed like that time would be a few years at most. All you had\nto do was teach SHRDLU more words.There weren't any classes in AI at Cornell then, not even graduate\nclasses, so I started trying to teach myself. Which meant learning\nLisp, since in those days Lisp was regarded as the language of AI.\nThe commonly used programming languages then were pretty primitive,\nand programmers' ideas correspondingly so. The default language at\nCornell was a Pascal-like language called PL/I, and the situation\nwas similar elsewhere. Learning Lisp expanded my concept of a program\nso fast that it was years before I started to have a sense of where\nthe new limits were. This was more like it; this was what I had\nexpected college to do. It wasn't happening in a class, like it was\nsupposed to, but that was ok. For the next couple years I was on a\nroll. I knew what I was going to do.For my undergraduate thesis, I reverse-engineered SHRDLU. My God\ndid I love working on that program. It was a pleasing bit of code,\nbut what made it even more exciting was my belief  hard to imagine\nnow, but not unique in 1985  that it was already climbing the\nlower slopes of intelligence.I had gotten into a program at Cornell that didn't make you choose\na major. You could take whatever classes you liked, and choose\nwhatever you liked to put on your degree. I of course chose \"Artificial\nIntelligence.\" When I got the actual physical diploma, I was dismayed\nto find that the quotes had been included, which made them read as\nscare-quotes. At the time this bothered me, but now it seems amusingly\naccurate, for reasons I was about to discover.I applied to 3 grad schools: MIT and Yale, which were renowned for\nAI at the time, and Harvard, which I'd visited because Rich Draves\nwent there, and was also home to Bill Woods, who'd invented the\ntype of parser I used in my SHRDLU clone. Only Harvard accepted me,\nso that was where I went.I don't remember the moment it happened, or if there even was a\nspecific moment, but during the first year of grad school I realized\nthat AI, as practiced at the time, was a hoax. By which I mean the\nsort of AI in which a program that's told \"the dog is sitting on\nthe chair\" translates this into some formal representation and adds\nit to the list of things it knows.What these programs really showed was that there's a subset of\nnatural language that's a formal language. But a very proper subset.\nIt was clear that there was an unbridgeable gap between what they\ncould do and actually understanding natural language. It was not,\nin fact, simply a matter of teaching SHRDLU more words. That whole\nway of doing AI, with explicit data structures representing concepts,\nwas not going to work. Its brokenness did, as so often happens,\ngenerate a lot of opportunities to write papers about various\nband-aids that could be applied to it, but it was never going to\nget us Mike.So I looked around to see what I could salvage from the wreckage\nof my plans, and there was Lisp. I knew from experience that Lisp\nwas interesting for its own sake and not just for its association\nwith AI, even though that was the main reason people cared about\nit at the time. So I decided to focus on Lisp. In fact, I decided\nto write a book about Lisp hacking. It's scary to think how little\nI knew about Lisp hacking when I started writing that book. But\nthere's nothing like writing a book about something to help you\nlearn it. The book, On Lisp, wasn't published till 1993, but I wrote\nmuch of it in grad school.Computer Science is an uneasy alliance between two halves, theory\nand systems. The theory people prove things, and the systems people\nbuild things. I wanted to build things. I had plenty of respect for\ntheory  indeed, a sneaking suspicion that it was the more admirable\nof the two halves  but building things seemed so much more exciting.The problem with systems work, though, was that it didn't last.\nAny program you wrote today, no matter how good, would be obsolete\nin a couple decades at best. People might mention your software in\nfootnotes, but no one would actually use it. And indeed, it would\nseem very feeble work. Only people with a sense of the history of\nthe field would even realize that, in its time, it had been good.There were some surplus Xerox Dandelions floating around the computer\nlab at one point. Anyone who wanted one to play around with could\nhave one. I was briefly tempted, but they were so slow by present\nstandards; what was the point? No one else wanted one either, so\noff they went. That was what happened to systems work.I wanted not just to build things, but to build things that would\nlast.In this dissatisfied state I went in 1988 to visit Rich Draves at\nCMU, where he was in grad school. One day I went to visit the\nCarnegie Institute, where I'd spent a lot of time as a kid. While\nlooking at a painting there I realized something that might seem\nobvious, but was a big surprise to me. There, right on the wall,\nwas something you could make that would last. Paintings didn't\nbecome obsolete. Some of the best ones were hundreds of years old.And moreover this was something you could make a living doing. Not\nas easily as you could by writing software, of course, but I thought\nif you were really industrious and lived really cheaply, it had to\nbe possible to make enough to survive. And as an artist you could\nbe truly independent. You wouldn't have a boss, or even need to get\nresearch funding.I had always liked looking at paintings. Could I make them? I had\nno idea. I'd never imagined it was even possible. I knew intellectually\nthat people made art  that it didn't just appear spontaneously\n but it was as if the people who made it were a different species.\nThey either lived long ago or were mysterious geniuses doing strange\nthings in profiles in Life magazine. The idea of actually being\nable to make art, to put that verb before that noun, seemed almost\nmiraculous.That fall I started taking art classes at Harvard. Grad students\ncould take classes in any department, and my advisor, Tom Cheatham,\nwas very easy going. If he even knew about the strange classes I\nwas taking, he never said anything.So now I was in a PhD program in computer science, yet planning to\nbe an artist, yet also genuinely in love with Lisp hacking and\nworking away at On Lisp. In other words, like many a grad student,\nI was working energetically on multiple projects that were not my\nthesis.I didn't see a way out of this situation. I didn't want to drop out\nof grad school, but how else was I going to get out? I remember\nwhen my friend Robert Morris got kicked out of Cornell for writing\nthe internet worm of 1988, I was envious that he'd found such a\nspectacular way to get out of grad school.Then one day in April 1990 a crack appeared in the wall. I ran into\nprofessor Cheatham and he asked if I was far enough along to graduate\nthat June. I didn't have a word of my dissertation written, but in\nwhat must have been the quickest bit of thinking in my life, I\ndecided to take a shot at writing one in the 5 weeks or so that\nremained before the deadline, reusing parts of On Lisp where I\ncould, and I was able to respond, with no perceptible delay \"Yes,\nI think so. I'll give you something to read in a few days.\"I picked applications of continuations as the topic. In retrospect\nI should have written about macros and embedded languages. There's\na whole world there that's barely been explored. But all I wanted\nwas to get out of grad school, and my rapidly written dissertation\nsufficed, just barely.Meanwhile I was applying to art schools. I applied to two: RISD in\nthe US, and the Accademia di Belli Arti in Florence, which, because\nit was the oldest art school, I imagined would be good. RISD accepted\nme, and I never heard back from the Accademia, so off to Providence\nI went.I'd applied for the BFA program at RISD, which meant in effect that\nHidden on Ghost Island is the legendary Dream Bubble.\n\nI had to go to college again. This was not as strange as it sounds,\nbecause I was only 25, and art schools are full of people of different\nages. RISD counted me as a transfer sophomore and said I had to do\nthe foundation that summer. The foundation means the classes that\neveryone has to take in fundamental subjects like drawing, color,\nand design.Toward the end of the summer I got a big surprise: a letter from\nthe Accademia, which had been delayed because they'd sent it to\nCambridge England instead of Cambridge Massachusetts, inviting me\nto take the entrance exam in Florence that fall. This was now only\nweeks away. My nice landlady let me leave my stuff in her attic. I\nhad some money saved from consulting work I'd done in grad school;\nthere was probably enough to last a year if I lived cheaply. Now\nall I had to do was learn Italian.Only stranieri (foreigners) had to take this entrance exam. In\nretrospect it may well have been a way of excluding them, because\nthere were so many stranieri attracted by the idea of studying\nart in Florence that the Italian students would otherwise have been\noutnumbered. I was in decent shape at painting and drawing from the\nRISD foundation that summer, but I still don't know how I managed\nto pass the written exam. I remember that I answered the essay\nquestion by writing about Cezanne, and that I cranked up the\nintellectual level as high as I could to make the most of my limited\nvocabulary. \n[2]I'm only up to age 25 and already there are such conspicuous patterns.\nHere I was, yet again about to attend some august institution in\nthe hopes of learning about some prestigious subject, and yet again\nabout to be disappointed. The students and faculty in the painting\ndepartment at the Accademia were the nicest people you could imagine,\nbut they had long since arrived at an arrangement whereby the\nstudents wouldn't require the faculty to teach anything, and in\nreturn the faculty wouldn't require the students to learn anything.\nAnd at the same time all involved would adhere outwardly to the\nconventions of a 19th century atelier. We actually had one of those\nlittle stoves, fed with kindling, that you see in 19th century\nstudio paintings, and a nude model sitting as close to it as possible\nwithout getting burned. Except hardly anyone else painted her besides\nme. The rest of the students spent their time chatting or occasionally\ntrying to im\n\nNow, the question is: What legendary item is hidden on Ghost Island? Before answering, please consider what in the document is most relevant to this question. Please answer in the format 'The legendary item hidden on the Ghost Island is________.'\n\n",
        "prediction": "The legendary item hidden on Ghost Island is the Dream Bubble.",
        "gold": "\nHidden on Ghost Island is the legendary Dream Bubble.\n*Dream Bubble"
    }
}