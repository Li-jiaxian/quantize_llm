datasets = [
    [
        dict(
            abbr='Length2000Depth78_2needle_en_4k',
            depth=78,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth84_2needle_en_4k',
            depth=84,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth89_2needle_en_4k',
            depth=89,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth94_2needle_en_4k',
            depth=94,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth100_2needle_en_4k',
            depth=100,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth0_2needle_en_4k',
            depth=0,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth5_2needle_en_4k',
            depth=5,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth10_2needle_en_4k',
            depth=10,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth15_2needle_en_4k',
            depth=15,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth21_2needle_en_4k',
            depth=21,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth26_2needle_en_4k',
            depth=26,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth31_2needle_en_4k',
            depth=31,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth36_2needle_en_4k',
            depth=36,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth42_2needle_en_4k',
            depth=42,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth47_2needle_en_4k',
            depth=47,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth52_2needle_en_4k',
            depth=52,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth57_2needle_en_4k',
            depth=57,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth63_2needle_en_4k',
            depth=63,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth68_2needle_en_4k',
            depth=68,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth73_2needle_en_4k',
            depth=73,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth78_2needle_en_4k',
            depth=78,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth84_2needle_en_4k',
            depth=84,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth89_2needle_en_4k',
            depth=89,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth94_2needle_en_4k',
            depth=94,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length3000Depth100_2needle_en_4k',
            depth=100,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
    ],
]
models = [
    dict(
        abbr='longchat-7b-hf',
        batch_padding=False,
        batch_size=8,
        max_seq_len=16384,
        model_kwargs=dict(device_map='auto'),
        path='/opt/data/private/hf_models/longchat-7b-16k',
        run_cfg=dict(num_gpus=1, num_procs=1),
        tokenizer_kwargs=dict(
            padding_side='left', truncation_side='left', use_fast=False),
        tokenizer_path='/opt/data/private/hf_models/longchat-7b-16k',
        type='opencompass.models.HuggingFaceCausalLM'),
]
work_dir = './outputs/needlebench/20240517_003144'
