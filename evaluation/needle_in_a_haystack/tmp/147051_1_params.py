datasets = [
    [
        dict(
            abbr='Length3000_parallel_en_4k',
            depths=[
                0,
                5,
                10,
                15,
                21,
                26,
                31,
                36,
                42,
                47,
                52,
                57,
                63,
                68,
                73,
                78,
                84,
                89,
                94,
                100,
            ],
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.parallel.NeedleBenchParallelEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=3000,
            length_buffer=1000,
            needle_file_name='needles.jsonl',
            num_repeats_per_file=25,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.parallel.NeedleBenchParallelDataset'
        ),
        dict(
            abbr='Length4000_parallel_en_4k',
            depths=[
                0,
                5,
                10,
                15,
                21,
                26,
                31,
                36,
                42,
                47,
                52,
                57,
                63,
                68,
                73,
                78,
                84,
                89,
                94,
                100,
            ],
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.parallel.NeedleBenchParallelEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=4000,
            length_buffer=1000,
            needle_file_name='needles.jsonl',
            num_repeats_per_file=25,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.parallel.NeedleBenchParallelDataset'
        ),
        dict(
            abbr='Length1000_parallel_zh_4k',
            depths=[
                0,
                5,
                10,
                15,
                21,
                26,
                31,
                36,
                42,
                47,
                52,
                57,
                63,
                68,
                73,
                78,
                84,
                89,
                94,
                100,
            ],
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.parallel.NeedleBenchParallelEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'zh_finance.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='Chinese',
            length=1000,
            length_buffer=200,
            needle_file_name='needles.jsonl',
            num_repeats_per_file=25,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.parallel.NeedleBenchParallelDataset'
        ),
        dict(
            abbr='Length2000_parallel_zh_4k',
            depths=[
                0,
                5,
                10,
                15,
                21,
                26,
                31,
                36,
                42,
                47,
                52,
                57,
                63,
                68,
                73,
                78,
                84,
                89,
                94,
                100,
            ],
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.parallel.NeedleBenchParallelEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'zh_finance.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='Chinese',
            length=2000,
            length_buffer=200,
            needle_file_name='needles.jsonl',
            num_repeats_per_file=25,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.parallel.NeedleBenchParallelDataset'
        ),
        dict(
            abbr='Length3000_parallel_zh_4k',
            depths=[
                0,
                5,
                10,
                15,
                21,
                26,
                31,
                36,
                42,
                47,
                52,
                57,
                63,
                68,
                73,
                78,
                84,
                89,
                94,
                100,
            ],
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.parallel.NeedleBenchParallelEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'zh_finance.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='Chinese',
            length=3000,
            length_buffer=200,
            needle_file_name='needles.jsonl',
            num_repeats_per_file=25,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.parallel.NeedleBenchParallelDataset'
        ),
        dict(
            abbr='Length4000_parallel_zh_4k',
            depths=[
                0,
                5,
                10,
                15,
                21,
                26,
                31,
                36,
                42,
                47,
                52,
                57,
                63,
                68,
                73,
                78,
                84,
                89,
                94,
                100,
            ],
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.parallel.NeedleBenchParallelEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'zh_finance.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='Chinese',
            length=4000,
            length_buffer=200,
            needle_file_name='needles.jsonl',
            num_repeats_per_file=25,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.parallel.NeedleBenchParallelDataset'
        ),
        dict(
            abbr='Length1000Depth0_2needle_en_4k',
            depth=0,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth5_2needle_en_4k',
            depth=5,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth10_2needle_en_4k',
            depth=10,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth15_2needle_en_4k',
            depth=15,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth21_2needle_en_4k',
            depth=21,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth26_2needle_en_4k',
            depth=26,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth31_2needle_en_4k',
            depth=31,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth36_2needle_en_4k',
            depth=36,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth42_2needle_en_4k',
            depth=42,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth47_2needle_en_4k',
            depth=47,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=2,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
    ],
]
models = [
    dict(
        abbr='longchat-7b-hf',
        batch_padding=False,
        batch_size=8,
        max_seq_len=16384,
        model_kwargs=dict(device_map='auto'),
        path='/opt/data/private/hf_models/longchat-7b-16k',
        run_cfg=dict(num_gpus=1, num_procs=1),
        tokenizer_kwargs=dict(
            padding_side='left', truncation_side='left', use_fast=False),
        tokenizer_path='/opt/data/private/hf_models/longchat-7b-16k',
        type='opencompass.models.HuggingFaceCausalLM'),
]
work_dir = './outputs/needlebench/20240517_003144'
