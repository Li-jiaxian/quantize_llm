datasets = [
    [
        dict(
            abbr='Length1000Depth0_4needle_en_4k',
            depth=0,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth5_4needle_en_4k',
            depth=5,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth10_4needle_en_4k',
            depth=10,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth15_4needle_en_4k',
            depth=15,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth21_4needle_en_4k',
            depth=21,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth26_4needle_en_4k',
            depth=26,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth31_4needle_en_4k',
            depth=31,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth36_4needle_en_4k',
            depth=36,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth42_4needle_en_4k',
            depth=42,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth47_4needle_en_4k',
            depth=47,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth52_4needle_en_4k',
            depth=52,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth57_4needle_en_4k',
            depth=57,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth63_4needle_en_4k',
            depth=63,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth68_4needle_en_4k',
            depth=68,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth73_4needle_en_4k',
            depth=73,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth78_4needle_en_4k',
            depth=78,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth84_4needle_en_4k',
            depth=84,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth89_4needle_en_4k',
            depth=89,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth94_4needle_en_4k',
            depth=94,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length1000Depth100_4needle_en_4k',
            depth=100,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=1000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth0_4needle_en_4k',
            depth=0,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth5_4needle_en_4k',
            depth=5,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth10_4needle_en_4k',
            depth=10,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth15_4needle_en_4k',
            depth=15,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
        dict(
            abbr='Length2000Depth21_4needle_en_4k',
            depth=21,
            diff=10,
            eval_cfg=dict(
                dataset_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_dataset_postprocess'
                ),
                evaluator=dict(
                    type=
                    'opencompass.datasets.needlebench.multi.NeedleBenchMultiEvaluator'
                ),
                pred_postprocessor=dict(
                    type=
                    'opencompass.datasets.needlebench.origin.needlebench_postprocess'
                ),
                pred_role='BOT'),
            file_list=[
                'PaulGrahamEssays.jsonl',
            ],
            guide=True,
            infer_cfg=dict(
                inferencer=dict(
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(prompt='{prompt}', role='HUMAN'),
                        dict(prompt='{answer}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            language='English',
            length=2000,
            length_buffer=600,
            needle_file_name='multi_needle_reasoning_en.json',
            num_needles=4,
            num_repeats_per_file=10,
            path=
            '/opt/data/private/ljx/quantize-llm/evaluation/needle_in_a_haystack/needlebench',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ], output_column='answer'),
            tokenizer_model='gpt-4',
            type=
            'opencompass.datasets.needlebench.multi.NeedleBenchMultiDataset'),
    ],
]
models = [
    dict(
        abbr='longchat-7b-hf',
        batch_padding=False,
        batch_size=8,
        max_out_len=450,
        max_seq_len=16384,
        model_kwargs=dict(device_map='auto'),
        path='/opt/data/private/hf_models/longchat-7b-16k',
        run_cfg=dict(num_gpus=1, num_procs=1),
        tokenizer_kwargs=dict(
            padding_side='left', truncation_side='left', use_fast=False),
        tokenizer_path='/opt/data/private/hf_models/longchat-7b-16k',
        type='opencompass.models.HuggingFaceCausalLM'),
]
work_dir = './outputs/needlebench/20240517_004548'
